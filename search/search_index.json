{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs \u00b6 For full documentation visit mkdocs.org . Commands \u00b6 mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout \u00b6 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files. x = 2 tesrjbhjg","title":"Home"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files. x = 2 tesrjbhjg","title":"Project layout"},{"location":"Collecting_results/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); import qcportal as ptl from qcsubmit.results import OptimizationCollectionResult client = ptl . FractalClient () client . list_collections ( 'OptimizationDataset' ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } tagline collection name OptimizationDataset FDA Optimization Dataset 1 None JGI Metabolite Set 1 None Kinase Inhibitors: WBO Distributions None OpenFF Discrepancy Benchmark 1 None OpenFF Full Optimization Benchmark 1 None OpenFF Gen 2 Opt Set 1 Roche None OpenFF Gen 2 Opt Set 2 Coverage None OpenFF Gen 2 Opt Set 3 Pfizer Discrepancy None OpenFF Gen 2 Opt Set 4 eMolecules Discrepancy None OpenFF Gen 2 Opt Set 5 Bayer None OpenFF NCI250K Boron 1 None OpenFF Optimization Set 1 None OpenFF Primary Optimization Benchmark 1 None OpenFF VEHICLe Set 1 None PEI None Pfizer Discrepancy Optimization Dataset 1 None QM8-T None SMIRNOFF Coverage Set 1 None ds = client . get_collection ( 'OptimizationDataset' , \"OpenFF Full Optimization Benchmark 1\" ) Here we want to pull down a few optimizations from this dataset with their full trajectories. % time result = OptimizationCollectionResult . from_server ( client = client , dataset_name = \"OpenFF Full Optimization Benchmark 1\" , spec_name = \"default\" , include_trajectory = True , subset = list ( ds . data . records . keys ())[: 20 ]) requested molecules 743 requested results 743 CPU times: user 3.02 s, sys: 495 ms, total: 3.52 s Wall time: 1min 14s # view an optimization result . collection [ \"CO/N=C/1 \\\\ C[N@](C[C@H]1C[NH3+])c2c(cc3c(=O)c(cn(c3n2)C4CC4)C(=O)[O-])F\" ] . entries [ 2 ] . get_final_molecule () var element = $('#e067b158-1266-45db-b41d-6606f2cdfd27'); {\"model_id\": \"ebd5ce6a521c4cf2972d9b4b63c72fad\", \"version_major\": 2, \"version_minor\": 0}","title":"Collecting Results"},{"location":"base_component/","text":"BasicSettings \u00b6 This mixin identifies the class as being basic and always being available as it only requires basic packages. is_available () (staticmethod) \u00b6 Show source code in workflow_components/base_component.py 167 168 169 170 171 172 173 @staticmethod def is_available () -> bool : \"\"\" This component is basic if it requires no extra dependencies. \"\"\" return True This component is basic if it requires no extra dependencies. provenance ( self ) \u00b6 Show source code in workflow_components/base_component.py 175 176 177 178 179 180 181 182 183 184 185 186 187 188 def provenance ( self ) -> Dict : \"\"\" The basic settings provenance generator. \"\"\" import openforcefield import qcsubmit provenance = { \"OpenforcefieldToolkit\" : openforcefield . __version__ , \"QCSubmit\" : qcsubmit . __version__ , } return provenance The basic settings provenance generator. CustomWorkflowComponent \u00b6 This is an abstract base class which should be used to create all workflow components, following the design of this class should allow users to easily create new work flow components with out needing to change much of the dataset factory code apply ( self , molecules ) \u00b6 Show source code in workflow_components/base_component.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 @abc . abstractmethod def apply ( self , molecules : List [ Molecule ]) -> ComponentResult : \"\"\" This is the main feature of the workflow component which should accept a molecule, perform the component action and then return the Parameters: molecules: The list of molecules to be processed by this component. Returns: An instance of the [ComponentResult][qcsubmit.datasets.ComponentResult] class which handles collecting together molecules that pass and fail the component \"\"\" ... This is the main feature of the workflow component which should accept a molecule, perform the component action and then return the Parameters Name Type Description Default molecules List[openforcefield.topology.molecule.Molecule] The list of molecules to be processed by this component. required Returns Type Description ComponentResult An instance of the ComponentResult class which handles collecting together molecules that pass and fail the component fail_molecule ( self , molecule , component_result ) \u00b6 Show source code in workflow_components/base_component.py 81 82 83 84 85 86 87 88 89 90 91 92 93 def fail_molecule ( self , molecule : Molecule , component_result : ComponentResult ) -> None : \"\"\" A method to fail a molecule. Parameters: molecule: The instance of the molecule to be failed. component_result: The [ComponentResult][qcsubmit.datasets.ComponentResult] instance that the molecule should be added to. \"\"\" component_result . filter_molecule ( molecule ) A method to fail a molecule. Parameters Name Type Description Default molecule Molecule The instance of the molecule to be failed. required component_result ComponentResult The ComponentResult instance that the molecule should be added to. required is_available () (staticmethod) \u00b6 Show source code in workflow_components/base_component.py 27 28 29 30 31 32 33 34 35 36 @staticmethod @abc . abstractmethod def is_available () -> bool : \"\"\" This method should identify if the component can be used by checking if the requirements are available. Returns: `True` if the component can be used else `False` \"\"\" ... This method should identify if the component can be used by checking if the requirements are available. Returns Type Description bool True if the component can be used else False provenance ( self ) \u00b6 Show source code in workflow_components/base_component.py 54 55 56 57 58 59 60 61 62 63 @abc . abstractmethod def provenance ( self ) -> Dict : \"\"\" This function should detail the programs with version information and procedures called during activation of the workflow component. Returns: A dictionary containing the information about the component and the functions called. \"\"\" ... This function should detail the programs with version information and procedures called during activation of the workflow component. Returns Type Description Dict A dictionary containing the information about the component and the functions called. ToolkitValidator \u00b6 A pydantic mixin class that adds toolkit settings and validation along with provenance information. Note The provenance information and toolkit settings are handled by the ToolkitValidator mixin. is_available () (staticmethod) \u00b6 Show source code in workflow_components/base_component.py 149 150 151 152 153 154 155 156 157 158 159 @staticmethod def is_available () -> bool : \"\"\" Check if any of the requested backend toolkits can be used. \"\"\" for toolkit in ToolkitValidator . _toolkits . values (): if toolkit . is_available (): return True else : return False Check if any of the requested backend toolkits can be used. provenance ( self ) \u00b6 Show source code in workflow_components/base_component.py 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 def provenance ( self ) -> Dict : \"\"\" This component calls the OFFTK to perform the task and logs information on the backend toolkit used. Returns: A dictionary containing the version information about the backend toolkit called to perform the task. \"\"\" import openforcefield import qcsubmit provenance = { \"OpenforcefieldToolkit\" : openforcefield . __version__ , \"QCSubmit\" : qcsubmit . __version__ , } if self . toolkit == \"rdkit\" : import rdkit provenance [ \"rdkit\" ] = rdkit . __version__ elif self . toolkit == \"openeye\" : import openeye provenance [ \"openeye\" ] = openeye . __version__ return provenance This component calls the OFFTK to perform the task and logs information on the backend toolkit used. Returns Type Description Dict A dictionary containing the version information about the backend toolkit called to perform the task.","title":"Base Component"},{"location":"base_component/#qcsubmit.workflow_components.base_component.BasicSettings","text":"This mixin identifies the class as being basic and always being available as it only requires basic packages.","title":"BasicSettings"},{"location":"base_component/#qcsubmit.workflow_components.base_component.BasicSettings.is_available","text":"Show source code in workflow_components/base_component.py 167 168 169 170 171 172 173 @staticmethod def is_available () -> bool : \"\"\" This component is basic if it requires no extra dependencies. \"\"\" return True This component is basic if it requires no extra dependencies.","title":"is_available()"},{"location":"base_component/#qcsubmit.workflow_components.base_component.BasicSettings.provenance","text":"Show source code in workflow_components/base_component.py 175 176 177 178 179 180 181 182 183 184 185 186 187 188 def provenance ( self ) -> Dict : \"\"\" The basic settings provenance generator. \"\"\" import openforcefield import qcsubmit provenance = { \"OpenforcefieldToolkit\" : openforcefield . __version__ , \"QCSubmit\" : qcsubmit . __version__ , } return provenance The basic settings provenance generator.","title":"provenance()"},{"location":"base_component/#qcsubmit.workflow_components.base_component.CustomWorkflowComponent","text":"This is an abstract base class which should be used to create all workflow components, following the design of this class should allow users to easily create new work flow components with out needing to change much of the dataset factory code","title":"CustomWorkflowComponent"},{"location":"base_component/#qcsubmit.workflow_components.base_component.CustomWorkflowComponent.apply","text":"Show source code in workflow_components/base_component.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 @abc . abstractmethod def apply ( self , molecules : List [ Molecule ]) -> ComponentResult : \"\"\" This is the main feature of the workflow component which should accept a molecule, perform the component action and then return the Parameters: molecules: The list of molecules to be processed by this component. Returns: An instance of the [ComponentResult][qcsubmit.datasets.ComponentResult] class which handles collecting together molecules that pass and fail the component \"\"\" ... This is the main feature of the workflow component which should accept a molecule, perform the component action and then return the Parameters Name Type Description Default molecules List[openforcefield.topology.molecule.Molecule] The list of molecules to be processed by this component. required Returns Type Description ComponentResult An instance of the ComponentResult class which handles collecting together molecules that pass and fail the component","title":"apply()"},{"location":"base_component/#qcsubmit.workflow_components.base_component.CustomWorkflowComponent.fail_molecule","text":"Show source code in workflow_components/base_component.py 81 82 83 84 85 86 87 88 89 90 91 92 93 def fail_molecule ( self , molecule : Molecule , component_result : ComponentResult ) -> None : \"\"\" A method to fail a molecule. Parameters: molecule: The instance of the molecule to be failed. component_result: The [ComponentResult][qcsubmit.datasets.ComponentResult] instance that the molecule should be added to. \"\"\" component_result . filter_molecule ( molecule ) A method to fail a molecule. Parameters Name Type Description Default molecule Molecule The instance of the molecule to be failed. required component_result ComponentResult The ComponentResult instance that the molecule should be added to. required","title":"fail_molecule()"},{"location":"base_component/#qcsubmit.workflow_components.base_component.CustomWorkflowComponent.is_available","text":"Show source code in workflow_components/base_component.py 27 28 29 30 31 32 33 34 35 36 @staticmethod @abc . abstractmethod def is_available () -> bool : \"\"\" This method should identify if the component can be used by checking if the requirements are available. Returns: `True` if the component can be used else `False` \"\"\" ... This method should identify if the component can be used by checking if the requirements are available. Returns Type Description bool True if the component can be used else False","title":"is_available()"},{"location":"base_component/#qcsubmit.workflow_components.base_component.CustomWorkflowComponent.provenance","text":"Show source code in workflow_components/base_component.py 54 55 56 57 58 59 60 61 62 63 @abc . abstractmethod def provenance ( self ) -> Dict : \"\"\" This function should detail the programs with version information and procedures called during activation of the workflow component. Returns: A dictionary containing the information about the component and the functions called. \"\"\" ... This function should detail the programs with version information and procedures called during activation of the workflow component. Returns Type Description Dict A dictionary containing the information about the component and the functions called.","title":"provenance()"},{"location":"base_component/#qcsubmit.workflow_components.base_component.ToolkitValidator","text":"A pydantic mixin class that adds toolkit settings and validation along with provenance information. Note The provenance information and toolkit settings are handled by the ToolkitValidator mixin.","title":"ToolkitValidator"},{"location":"base_component/#qcsubmit.workflow_components.base_component.ToolkitValidator.is_available","text":"Show source code in workflow_components/base_component.py 149 150 151 152 153 154 155 156 157 158 159 @staticmethod def is_available () -> bool : \"\"\" Check if any of the requested backend toolkits can be used. \"\"\" for toolkit in ToolkitValidator . _toolkits . values (): if toolkit . is_available (): return True else : return False Check if any of the requested backend toolkits can be used.","title":"is_available()"},{"location":"base_component/#qcsubmit.workflow_components.base_component.ToolkitValidator.provenance","text":"Show source code in workflow_components/base_component.py 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 def provenance ( self ) -> Dict : \"\"\" This component calls the OFFTK to perform the task and logs information on the backend toolkit used. Returns: A dictionary containing the version information about the backend toolkit called to perform the task. \"\"\" import openforcefield import qcsubmit provenance = { \"OpenforcefieldToolkit\" : openforcefield . __version__ , \"QCSubmit\" : qcsubmit . __version__ , } if self . toolkit == \"rdkit\" : import rdkit provenance [ \"rdkit\" ] = rdkit . __version__ elif self . toolkit == \"openeye\" : import openeye provenance [ \"openeye\" ] = openeye . __version__ return provenance This component calls the OFFTK to perform the task and logs information on the backend toolkit used. Returns Type Description Dict A dictionary containing the version information about the backend toolkit called to perform the task.","title":"provenance()"},{"location":"conformer_generation/","text":"StandardConformerGenerator \u00b6 Standard conformer generator using the OFFTK and the back end toolkits. Note The provenance information and toolkit settings are handled by the ToolkitValidator mixin. apply ( self , molecules ) \u00b6 Show source code in workflow_components/conformer_generation.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 def apply ( self , molecules : List [ Molecule ]) -> ComponentResult : \"\"\" Generate conformers for the molecules using the selected toolkit backend. Parameters: molecules: The list of molecules the component should be applied on. Returns: A [ComponentResult][qcsubmit.datasets.ComponentResult] instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result. \"\"\" result = self . _create_result () # create the toolkit toolkit = self . _toolkits [ self . toolkit ]() for molecule in molecules : try : molecule . generate_conformers ( n_conformers = self . max_conformers , clear_existing = self . clear_existing , toolkit_registry = toolkit , ) # need to catch more specific exceptions here. except Exception : self . fail_molecule ( molecule = molecule , component_result = result ) finally : # if we could not produce a conformer then fail the molecule if molecule . n_conformers == 0 : self . fail_molecule ( molecule = molecule , component_result = result ) else : result . add_molecule ( molecule ) return result Generate conformers for the molecules using the selected toolkit backend. Parameters Name Type Description Default molecules List[openforcefield.topology.molecule.Molecule] The list of molecules the component should be applied on. required Returns Type Description ComponentResult A ComponentResult instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result.","title":"Conformer Generation"},{"location":"conformer_generation/#qcsubmit.workflow_components.conformer_generation.StandardConformerGenerator","text":"Standard conformer generator using the OFFTK and the back end toolkits. Note The provenance information and toolkit settings are handled by the ToolkitValidator mixin.","title":"StandardConformerGenerator"},{"location":"conformer_generation/#qcsubmit.workflow_components.conformer_generation.StandardConformerGenerator.apply","text":"Show source code in workflow_components/conformer_generation.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 def apply ( self , molecules : List [ Molecule ]) -> ComponentResult : \"\"\" Generate conformers for the molecules using the selected toolkit backend. Parameters: molecules: The list of molecules the component should be applied on. Returns: A [ComponentResult][qcsubmit.datasets.ComponentResult] instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result. \"\"\" result = self . _create_result () # create the toolkit toolkit = self . _toolkits [ self . toolkit ]() for molecule in molecules : try : molecule . generate_conformers ( n_conformers = self . max_conformers , clear_existing = self . clear_existing , toolkit_registry = toolkit , ) # need to catch more specific exceptions here. except Exception : self . fail_molecule ( molecule = molecule , component_result = result ) finally : # if we could not produce a conformer then fail the molecule if molecule . n_conformers == 0 : self . fail_molecule ( molecule = molecule , component_result = result ) else : result . add_molecule ( molecule ) return result Generate conformers for the molecules using the selected toolkit backend. Parameters Name Type Description Default molecules List[openforcefield.topology.molecule.Molecule] The list of molecules the component should be applied on. required Returns Type Description ComponentResult A ComponentResult instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result.","title":"apply()"},{"location":"datasets/","text":"BasicDataset \u00b6 The general qcfractal dataset class which contains all of the molecules and information about them prior to submission. The class is a simple holder of the dataset and information about it and can do simple checks on the data before submitting it such as ensuring that the molecules have cmiles information and a unique index to be identified by. Note The molecules in this dataset are all expanded so that different conformers are unique submissions. components : List [ Dict [ str , Union [ str , Dict [ str , str ]]]] (property, readonly) \u00b6 Gather the details of the components that were ran during the creation of this dataset. Returns Type Description List[Dict[str, Union[str, Dict[str, str]]]] A list of dictionaries containing information about the components ran during the generation of the dataset. filtered : Molecule (property, readonly) \u00b6 A generator for the molecules that have been filtered. Returns Type Description Molecule offmol: A molecule representation created from the filtered molecule lists Note Modifying the molecule will have no effect on the data stored. molecules : Molecule (property, readonly) \u00b6 A generator that creates an openforcefield.topology.Molecule one by one from the dataset. Returns Type Description Molecule The instance of the molecule from the dataset. Note Editing the molecule will not effect the data stored in the dataset as it is immutable. n_components : int (property, readonly) \u00b6 Return the amount of components that have been ran during generating the dataset. Returns Type Description int The number of components that were ran while generating the dataset. n_filtered : int (property, readonly) \u00b6 Calculate the total number of molecules filtered by the components used in a workflow to create this dataset. Returns Type Description int filtered: The total number of molecules filtered by components. n_molecules : int (property, readonly) \u00b6 Calculate the total number of unique molecules which will be submitted as part of this dataset. Returns Type Description int The number of molecules in the dataset. Note The number of molecule records submitted is not always the same as the amount of records created, this can also be checked using n_records . Here we give the number of unique molecules not excluding conformers. * see also [n_conformers][qcsubmit.datasets.BasicDataset.n_conformers] n_records : int (property, readonly) \u00b6 Return the total number of records that will be created on submission of the dataset. Returns Type Description int The number of records that will be added to the collection. Note The number returned will be different depending on the dataset used. The amount of unqiue molecule can be found using n_molecules see also the n_molecules __json_encoder__ ( obj ) (staticmethod) \u00b6 partial(func, args, *keywords) - new function with partial application of the given arguments and keywords. add_molecule ( self , index , molecule , attributes , extras = None , keywords = None , ** kwargs ) \u00b6 Show source code in qcsubmit/datasets.py 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 def add_molecule ( self , index : str , molecule : off . Molecule , attributes : Dict [ str , Any ], extras : Optional [ Dict [ str , Any ]] = None , keywords : Optional [ Dict [ str , Any ]] = None , ** kwargs , ) -> None : \"\"\" Add a molecule to the dataset under the given index with the passed cmiles. Parameters: index : str The molecule index that was generated by the factory. molecule : openforcefield.topology.Molecule The instance of the molecule which contains its conformer information. attributes : Dict[str, str] The attributes dictionary containing all of the relevant identifier tags for the molecule and extra meta information on the calculation. extras : Dict[str, Any], optional, default=None The extras that should be supplied into the qcportal.moldels.Molecule. keywords : Dict[str, Any], optional, default=None, Any extra keywords which are required for the calculation. Note: Each molecule in this basic dataset should have all of its conformers expanded out into separate entries. Thus here we take the general molecule index and increment it. \"\"\" try : data_entry = DatasetEntry ( off_molecule = molecule , index = index , attributes = attributes , extras = extras , keywords = keywords , ** kwargs , ) self . dataset [ index ] = data_entry except qcel . exceptions . ValidationError : # the molecule has some qcschema issue and should be removed self . filter_molecules ( molecules = molecule , component_name = \"QCSchemaIssues\" , component_description = { \"component_description\" : \"The molecule was removed as a valid QCSchema could not be made\" , \"component_name\" : \"QCSchemaIssues\" , }, component_provenance = self . provenance , ) Add a molecule to the dataset under the given index with the passed cmiles. Parameters Name Type Description Default index : str The molecule index that was generated by the factory. molecule : openforcefield.topology.Molecule The instance of the molecule which contains its conformer information. attributes : Dict[str, str] The attributes dictionary containing all of the relevant identifier tags for the molecule and extra meta information on the calculation. extras : Dict[str, Any], optional, default=None The extras that should be supplied into the qcportal.moldels.Molecule. keywords : Dict[str, Any], optional, default=None, Any extra keywords which are required for the calculation. Note Each molecule in this basic dataset should have all of its conformers expanded out into separate entries. Thus here we take the general molecule index and increment it. coverage_report ( self , forcefields ) \u00b6 Show source code in qcsubmit/datasets.py 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 def coverage_report ( self , forcefields : List [ str ]) -> Dict : \"\"\" Produce a coverage report of all of the parameters that are exercised by the molecules in the dataset. Parameters: forcefields: The name of the openforcefield force field which should be included in the coverage report. Returns: A dictionary for each of the force fields which break down which parameters are exercised by their parameter type. \"\"\" from openforcefield.typing.engines.smirnoff import ForceField from openforcefield.utils.structure import get_molecule_parameterIDs coverage = {} param_types = { \"a\" : \"Angles\" , \"b\" : \"Bonds\" , \"c\" : \"Constraints\" , \"t\" : \"ProperTorsions\" , \"i\" : \"ImproperTorsions\" , \"n\" : \"vdW\" , } if isinstance ( forcefields , str ): forcefields = [ forcefields ] for forcefield in forcefields : result = {} ff = ForceField ( forcefield ) parameters_by_molecule , parameters_by_id = get_molecule_parameterIDs ( list ( self . molecules ), ff ) # now create the the dict to store the ids used for param_id in parameters_by_id . keys (): result . setdefault ( param_types [ param_id [ 0 ]], []) . append ( param_id ) # now store the force field dict into the main result coverage [ forcefield ] = result return coverage Produce a coverage report of all of the parameters that are exercised by the molecules in the dataset. Parameters Name Type Description Default forcefields List[str] The name of the openforcefield force field which should be included in the coverage report. required Returns Type Description Dict A dictionary for each of the force fields which break down which parameters are exercised by their parameter type. export_dataset ( self , file_name ) \u00b6 Show source code in qcsubmit/datasets.py 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 def export_dataset ( self , file_name : str ) -> None : \"\"\" Export the dataset to file so that it can be used to make another dataset quickly. Parameters: file_name: The name of the file the dataset should be wrote to. Note: The supported file types are: - `json` Raises: UnsupportedFiletypeError: If the requested file type is not supported. \"\"\" file_type = file_name . split ( \".\" )[ - 1 ] if file_type == \"json\" : with open ( file_name , \"w\" ) as output : output . write ( self . json ( indent = 2 )) else : raise UnsupportedFiletypeError ( f \"The requested file type { file_type } is not supported please use \" f \"json or yaml\" ) Export the dataset to file so that it can be used to make another dataset quickly. Parameters Name Type Description Default file_name str The name of the file the dataset should be wrote to. required Note The supported file types are: json Exceptions Type Description UnsupportedFiletypeError If the requested file type is not supported. filter_molecules ( self , molecules , component_name , component_description , component_provenance ) \u00b6 Show source code in qcsubmit/datasets.py 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 def filter_molecules ( self , molecules : Union [ off . Molecule , List [ off . Molecule ]], component_name : str , component_description : Dict [ str , Any ], component_provenance : Dict [ str , str ], ) -> None : \"\"\" Filter a molecule or list of molecules by the component they failed. Parameters: molecules: A molecule or list of molecules to be filtered. component_description: The dictionary representation of the component that filtered this set of molecules. component_name: The name of the component. component_provenance: The dictionary representation of the component provenance. \"\"\" if isinstance ( molecules , off . Molecule ): # make into a list molecules = [ molecules ] if component_name in self . filtered_molecules : filter_mols = [ molecule . to_smiles ( isomeric = True , explicit_hydrogens = True ) for molecule in molecules ] self . filtered_molecules [ component_name ] . molecules . extend ( filter_mols ) else : filter_data = FilterEntry ( off_molecules = molecules , component_name = component_name , component_provenance = component_provenance , component_description = component_description , ) self . filtered_molecules [ filter_data . component_name ] = filter_data Filter a molecule or list of molecules by the component they failed. Parameters Name Type Description Default molecules: A molecule or list of molecules to be filtered. component_description: The dictionary representation of the component that filtered this set of molecules. component_name: The name of the component. component_provenance: The dictionary representation of the component provenance. molecules_to_file ( self , file_name , file_type ) \u00b6 Show source code in qcsubmit/datasets.py 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 def molecules_to_file ( self , file_name : str , file_type : str ) -> None : \"\"\" Write the molecules to the requested file type. Important: The supported file types are: - SMI - INCHI - INCKIKEY \"\"\" file_writers = { \"smi\" : self . _molecules_to_smiles , \"inchi\" : self . _molecules_to_inchi , \"inchikey\" : self . _molecules_to_inchikey , } try : # get the list of molecules molecules = file_writers [ file_type . lower ()]() with open ( file_name , \"w\" ) as output : for molecule in molecules : output . write ( f \" { molecule } \\n \" ) except KeyError : raise UnsupportedFiletypeError ( f \"The requested file type { file_type } is not supported, supported types are\" f \" { file_writers . keys () } .\" ) Write the molecules to the requested file type. Important The supported file types are: SMI INCHI INCKIKEY submit ( self , client , await_result = False ) \u00b6 Show source code in qcsubmit/datasets.py 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 def submit ( self , client : Union [ str , ptl . FractalClient ], await_result : Optional [ bool ] = False , ) -> SingleResult : \"\"\" Submit the dataset to the chosen qcarchive address and finish or wait for the results and return the corresponding result class. Parameters: client : Union[str, qcportal.FractalClient] The name of the file containing the client information or an actual client instance. await_result : bool, optional, default=False If the user wants to wait for the calculation to finish before returning. Returns: The collection of the results which have completed. \"\"\" target_client = self . _activate_client ( client ) # work out if we are extending a collection try : collection = target_client . get_collection ( \"Dataset\" , self . dataset_name ) except KeyError : collection = ptl . collections . Dataset ( name = self . dataset_name , client = target_client , default_driver = self . driver , default_program = self . program , tagline = self . dataset_tagline , tags = self . dataset_tags , description = self . description , provenance = self . provenance , metadata = self . metadata , ) # store the keyword set into the collection kw = ptl . models . KeywordSet ( values = self . dict ( include = { \"maxiter\" , \"scf_properties\" }) ) try : # try and add the keywords if present then continue collection . add_keywords ( alias = self . spec_name , program = self . program , keyword = kw , default = True ) collection . save () except ( KeyError , AttributeError ): pass i = 0 # now add the molecules to the database, saving every 30 for speed for index , data in self . dataset . items (): # check if the index we have been supplied has a number tag already if so start from this tag index , tag = self . _clean_index ( index = index ) for j , molecule in enumerate ( data . initial_molecules ): name = index + f \"- { tag + j } \" try : collection . add_entry ( name = name , molecule = molecule ) i += 1 except KeyError : continue finally : if i % 30 == 0 : # save the added entries collection . save () # save the final dataset collection . save () # submit the calculations response = collection . compute ( method = self . method , basis = self . basis , keywords = self . spec_name , program = self . program , tag = self . compute_tag , priority = self . priority , ) collection . save () return response Submit the dataset to the chosen qcarchive address and finish or wait for the results and return the corresponding result class. Parameters Name Type Description Default client : Union[str, qcportal.FractalClient] The name of the file containing the client information or an actual client instance. await_result : bool, optional, default=False If the user wants to wait for the calculation to finish before returning. Returns Type Description SingleResult The collection of the results which have completed. ComponentResult \u00b6 Class to contain molecules after the execution of a workflow component this automatically applies de-duplication to the molecules. For example if a molecule is already in the molecules list it will not be added but any conformers will be kept and transferred. If a molecule in the molecules list is then filtered it will be removed from the molecules list. n_conformers : int (property, readonly) \u00b6 Returns Type Description int The number of conformers stored in the molecules. n_filtered : int (property, readonly) \u00b6 Returns Type Description int The number of filtered molecules. n_molecules : int (property, readonly) \u00b6 Returns Type Description int The number of molecules saved in the result. __init__ ( self , component_name , component_description , component_provenance , molecules = None , input_file = None ) \u00b6 Show source code in qcsubmit/datasets.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def __init__ ( self , component_name : str , component_description : Dict [ str , str ], component_provenance : Dict [ str , str ], molecules : Optional [ Union [ List [ off . Molecule ], off . Molecule ]] = None , input_file : Optional [ str ] = None , ): \"\"\"Register the list of molecules to process. Parameters: component_name: The name of the component that produced this result. component_description: The dictionary representation of the component which details the function and running parameters. component_provenance: The dictionary of the modules used and there version number when running the component. component_provenance: The dictionary of the provenance information about the component that was used to generate the data. molecules: The list of molecules that have been possessed by a component and returned as a result. input_file: The name of the input file used to produce the result if not from a component. \"\"\" self . molecules : List [ off . Molecule ] = [] self . filtered : List [ off . Molecule ] = [] self . component_name : str = component_name self . component_description : Dict = component_description self . component_provenance : Dict = component_provenance assert ( molecules is None or input_file is None ), \"Provide either a list of molecules or an input file name.\" # if we have an input file load it if input_file is not None : molecules = off . Molecule . from_file ( file_path = input_file , allow_undefined_stereo = True ) # now lets process the molecules and add them to the class if molecules is not None : for molecule in molecules : self . add_molecule ( molecule ) Register the list of molecules to process. Parameters Name Type Description Default component_name str The name of the component that produced this result. required component_description Dict[str, str] The dictionary representation of the component which details the function and running parameters. required component_provenance Dict[str, str] The dictionary of the modules used and there version number when running the component. required component_provenance Dict[str, str] The dictionary of the provenance information about the component that was used to generate the data. required molecules Optional[Union[List[openforcefield.topology.molecule.Molecule], openforcefield.topology.molecule.Molecule]] The list of molecules that have been possessed by a component and returned as a result. None input_file Optional[str] The name of the input file used to produce the result if not from a component. None add_molecule ( self , molecule ) \u00b6 Show source code in qcsubmit/datasets.py 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 def add_molecule ( self , molecule : off . Molecule ): \"\"\" Add a molecule to the molecule list after checking that it is not present already. If it is de-duplicate the record and condense the conformers. \"\"\" import numpy as np from simtk import unit if molecule in self . molecules : # we need to align the molecules and transfer the coords and properties mol_id = self . molecules . index ( molecule ) # get the mapping isomorphic , mapping = off . Molecule . are_isomorphic ( molecule , self . molecules [ mol_id ], return_atom_map = True ) assert isomorphic is True # transfer any torsion indexs for similar fragments if \"dihedrals\" in molecule . properties : # remap the dihedrals for dihedral , dihedral_range in molecule . properties [ \"dihedrals\" ] . items (): if len ( dihedral ) == 4 : mapped_dihedral = tuple ([ mapping [ i ] for i in dihedral ]) elif len ( dihedral ) == 2 : # this is a 2d dihedral mapped_dihedral = ( tuple ([ mapping [ i ] for i in dihedral [ 0 ]]), tuple ([ mapping [ i ] for i in dihedral [ 1 ]]), ) try : self . molecules [ mol_id ] . properties [ \"dihedrals\" ][ mapped_dihedral ] = dihedral_range except KeyError : self . molecules [ mol_id ] . properties [ \"dihedrals\" ] = { mapped_dihedral : dihedral_range } if molecule . n_conformers != 0 : # transfer the coordinates for conformer in molecule . conformers : new_conformer = np . zeros (( molecule . n_atoms , 3 )) for i in range ( molecule . n_atoms ): new_conformer [ i ] = conformer [ mapping [ i ]] . value_in_unit ( unit . angstrom ) new_conf = unit . Quantity ( value = new_conformer , unit = unit . angstrom ) # check if the conformer is already on the molecule for old_conformer in self . molecules [ mol_id ] . conformers : if old_conformer . tolist () == new_conf . tolist (): break else : self . molecules [ mol_id ] . add_conformer ( new_conformer * unit . angstrom ) else : # molecule already in list and coords not present so just return return else : self . molecules . append ( molecule ) Add a molecule to the molecule list after checking that it is not present already. If it is de-duplicate the record and condense the conformers. filter_molecule ( self , molecule ) \u00b6 Show source code in qcsubmit/datasets.py 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 def filter_molecule ( self , molecule : off . Molecule ): \"\"\" Filter out a molecule that has not passed this workflow component. If the molecule is already in the pass list remove it and ensure it is only in the filtered list. \"\"\" try : self . molecules . remove ( molecule ) except ValueError : pass finally : if molecule not in self . filtered : self . filtered . append ( molecule ) else : return Filter out a molecule that has not passed this workflow component. If the molecule is already in the pass list remove it and ensure it is only in the filtered list. DatasetEntry \u00b6 A basic data class to construct the datasets which holds any information about the molecule and options used in the qcarchive calculation. Note extras are passed into the qcelemental.models.Molecule on creation. any extras that should passed to the calculation like extra constrains should be passed to keywords . __init__ ( self , off_molecule = None , ** kwargs ) \u00b6 Show source code in qcsubmit/datasets.py 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 def __init__ ( self , off_molecule : off . Molecule = None , ** kwargs ): \"\"\" Init the dataclass handling conversions of the molecule first. This is needed to make sure the extras are passed into the qcschema molecule. \"\"\" extras = kwargs [ \"extras\" ] # if we get an off_molecule we need to convert it if off_molecule is not None : if off_molecule . n_conformers == 0 : off_molecule . generate_conformers ( n_conformers = 1 ) # TODO add extras here when we can schema_mols = [ off_molecule . to_qcschema ( conformer = conformer , extras = extras ) for conformer in range ( off_molecule . n_conformers ) ] kwargs [ \"initial_molecules\" ] = schema_mols super () . __init__ ( ** kwargs ) Init the dataclass handling conversions of the molecule first. This is needed to make sure the extras are passed into the qcschema molecule. __json_encoder__ ( obj ) (staticmethod) \u00b6 partial(func, args, *keywords) - new function with partial application of the given arguments and keywords. FilterEntry \u00b6 A basic data class that contains information on components run in a workflow and the associated molecules which were removed by it. __init__ ( self , off_molecules = None , ** kwargs ) \u00b6 Show source code in qcsubmit/datasets.py 247 248 249 250 251 252 253 254 255 256 257 def __init__ ( self , off_molecules : List [ off . Molecule ] = None , ** kwargs ): \"\"\" Init the dataclass handling conversions of the molecule first. \"\"\" molecules = [ molecule . to_smiles ( isomeric = True , explicit_hydrogens = True ) for molecule in off_molecules ] kwargs [ \"molecules\" ] = molecules super () . __init__ ( ** kwargs ) Init the dataclass handling conversions of the molecule first. __json_encoder__ ( obj ) (staticmethod) \u00b6 partial(func, args, *keywords) - new function with partial application of the given arguments and keywords. OptimizationDataset \u00b6 An optimisation dataset class which handles submission of settings differently from the basic dataset, and creates optimization datasets in the public or local qcarcive instance. __json_encoder__ ( obj ) (staticmethod) \u00b6 partial(func, args, *keywords) - new function with partial application of the given arguments and keywords. get_qc_spec ( self , keyword_id ) \u00b6 Show source code in qcsubmit/datasets.py 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 def get_qc_spec ( self , keyword_id : str ) -> QCSpecification : \"\"\" Create the QC specification for the computation. Parameters: keyword_id: The string of the keyword set id number. Returns: The dictionary representation of the QC specification \"\"\" qc_spec = QCSpecification ( driver = self . driver , method = self . method , basis = self . basis , keywords = keyword_id , program = self . program , ) return qc_spec Create the QC specification for the computation. Parameters Name Type Description Default keyword_id str The string of the keyword set id number. required Returns Type Description QCSpecification The dictionary representation of the QC specification submit ( self , client , await_result = False ) \u00b6 Show source code in qcsubmit/datasets.py 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 def submit ( self , client : Union [ str , ptl . FractalClient ], await_result : bool = False ) -> SingleResult : \"\"\" Submit the dataset to the chosen qcarchive address and finish or wait for the results and return the corresponding result class. Parameters: await_result: If the user wants to wait for the calculation to finish before returning. client: The name of the file containing the client information or the client instance. Returns: Either `None` if we are not waiting for the results or a BasicResult instance with all of the completed calculations. \"\"\" target_client = self . _activate_client ( client ) # work out if we are extending a collection try : collection = target_client . get_collection ( \"OptimizationDataset\" , self . dataset_name ) except KeyError : collection = ptl . collections . OptimizationDataset ( name = self . dataset_name , client = target_client , default_driver = self . driver , default_program = self . program , tagline = self . dataset_tagline , tags = self . dataset_tags , description = self . description , provenance = self . provenance , metadata = self . metadata , ) # store the keyword set into the collection kw_id = self . _add_keywords ( target_client ) # create the optimization specification opt_spec = self . optimization_procedure . get_optimzation_spec () # create the qc specification qc_spec = self . get_qc_spec ( keyword_id = kw_id ) collection . add_specification ( name = self . spec_name , optimization_spec = opt_spec , qc_spec = qc_spec , description = self . spec_description , overwrite = False , ) i = 0 # now add the molecules to the database, saving every 30 for speed for index , data in self . dataset . items (): # check if the index we have been supplied has a number tag already if so start from this tag index , tag = self . _clean_index ( index = index ) for j , molecule in enumerate ( data . initial_molecules ): name = index + f \"- { tag + j } \" try : collection . add_entry ( name = name , initial_molecule = molecule , attributes = data . attributes , additional_keywords = data . keywords , save = False , ) i += 1 except KeyError : continue finally : if i % 30 == 0 : # save the added entries collection . save () # save the added entries collection . save () # submit the calculations response = collection . compute ( specification = self . spec_name , tag = self . compute_tag , priority = self . priority ) return response Submit the dataset to the chosen qcarchive address and finish or wait for the results and return the corresponding result class. Parameters Name Type Description Default await_result bool If the user wants to wait for the calculation to finish before returning. False client Union[str, qcportal.client.FractalClient] The name of the file containing the client information or the client instance. required Returns Type Description SingleResult Either None if we are not waiting for the results or a BasicResult instance with all of the completed calculations. TorsiondriveDataset \u00b6 An torsiondrive dataset class which handles submission of settings differently from the basic dataset, and creates torsiondrive datasets in the public or local qcarcive instance. Important The dihedral_ranges for the whole dataset can be defined here or if different scan ranges are required on a case by case basis they can be defined for each torsion in a molecule separately in the properties attribute of the molecule. For example mol.properties['dihedral_range'] = (-165, 180) __json_encoder__ ( obj ) (staticmethod) \u00b6 partial(func, args, *keywords) - new function with partial application of the given arguments and keywords. submit ( self , client , await_result = False ) \u00b6 Show source code in qcsubmit/datasets.py 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 def submit ( self , client : Union [ str , ptl . FractalClient ], await_result : bool = False ) -> SingleResult : \"\"\" Submit the dataset to the chosen qcarchive address and finish or wait for the results and return the corresponding result class. Parameters: await_result: If the user wants to wait for the calculation to finish before returning. client: The name of the file containing the client information or the client instance. Returns: Either `None` if we are not waiting for the results or a BasicResult instance with all of the completed calculations. \"\"\" target_client = self . _activate_client ( client ) # work out if we are extending a collection try : collection = target_client . get_collection ( \"TorsionDriveDataset\" , self . dataset_name ) except KeyError : collection = ptl . collections . TorsionDriveDataset ( name = self . dataset_name , client = target_client , default_driver = self . driver , default_program = self . program , tagline = self . dataset_tagline , tags = self . dataset_tags , description = self . description , provenance = self . provenance , metadata = self . metadata , ) # store the keyword set into the collection kw_id = self . _add_keywords ( target_client ) # create the optimization specification opt_spec = self . optimization_procedure . get_optimzation_spec () # create the qc specification qc_spec = self . get_qc_spec ( keyword_id = kw_id ) collection . add_specification ( name = self . spec_name , optimization_spec = opt_spec , qc_spec = qc_spec , description = self . spec_description , overwrite = True , ) # start add the molecule to the dataset, multipule conformers/molecules can be used as the starting geometry for i , ( index , data ) in enumerate ( self . dataset . items ()): try : collection . add_entry ( name = index , initial_molecules = data . initial_molecules , dihedrals = data . dihedrals , grid_spacing = self . grid_spacings , energy_upper_limit = self . energy_upper_limit , attributes = data . attributes , energy_decrease_thresh = self . energy_decrease_thresh , dihedral_ranges = data . keywords . get ( \"dihedral_ranges\" , None ) or self . dihedral_ranges , ) except KeyError : continue finally : if i % 30 == 0 : collection . save () collection . save () # submit the calculations response = collection . compute ( specification = self . spec_name , tag = self . compute_tag , priority = self . priority ) return response Submit the dataset to the chosen qcarchive address and finish or wait for the results and return the corresponding result class. Parameters Name Type Description Default await_result bool If the user wants to wait for the calculation to finish before returning. False client Union[str, qcportal.client.FractalClient] The name of the file containing the client information or the client instance. required Returns Type Description SingleResult Either None if we are not waiting for the results or a BasicResult instance with all of the completed calculations.","title":"Datasets"},{"location":"datasets/#qcsubmit.datasets.BasicDataset","text":"The general qcfractal dataset class which contains all of the molecules and information about them prior to submission. The class is a simple holder of the dataset and information about it and can do simple checks on the data before submitting it such as ensuring that the molecules have cmiles information and a unique index to be identified by. Note The molecules in this dataset are all expanded so that different conformers are unique submissions.","title":"BasicDataset"},{"location":"datasets/#qcsubmit.datasets.BasicDataset.components","text":"Gather the details of the components that were ran during the creation of this dataset. Returns Type Description List[Dict[str, Union[str, Dict[str, str]]]] A list of dictionaries containing information about the components ran during the generation of the dataset.","title":"components"},{"location":"datasets/#qcsubmit.datasets.BasicDataset.filtered","text":"A generator for the molecules that have been filtered. Returns Type Description Molecule offmol: A molecule representation created from the filtered molecule lists Note Modifying the molecule will have no effect on the data stored.","title":"filtered"},{"location":"datasets/#qcsubmit.datasets.BasicDataset.molecules","text":"A generator that creates an openforcefield.topology.Molecule one by one from the dataset. Returns Type Description Molecule The instance of the molecule from the dataset. Note Editing the molecule will not effect the data stored in the dataset as it is immutable.","title":"molecules"},{"location":"datasets/#qcsubmit.datasets.BasicDataset.n_components","text":"Return the amount of components that have been ran during generating the dataset. Returns Type Description int The number of components that were ran while generating the dataset.","title":"n_components"},{"location":"datasets/#qcsubmit.datasets.BasicDataset.n_filtered","text":"Calculate the total number of molecules filtered by the components used in a workflow to create this dataset. Returns Type Description int filtered: The total number of molecules filtered by components.","title":"n_filtered"},{"location":"datasets/#qcsubmit.datasets.BasicDataset.n_molecules","text":"Calculate the total number of unique molecules which will be submitted as part of this dataset. Returns Type Description int The number of molecules in the dataset. Note The number of molecule records submitted is not always the same as the amount of records created, this can also be checked using n_records . Here we give the number of unique molecules not excluding conformers. * see also [n_conformers][qcsubmit.datasets.BasicDataset.n_conformers]","title":"n_molecules"},{"location":"datasets/#qcsubmit.datasets.BasicDataset.n_records","text":"Return the total number of records that will be created on submission of the dataset. Returns Type Description int The number of records that will be added to the collection. Note The number returned will be different depending on the dataset used. The amount of unqiue molecule can be found using n_molecules see also the n_molecules","title":"n_records"},{"location":"datasets/#qcsubmit.datasets.BasicDataset.add_molecule","text":"Show source code in qcsubmit/datasets.py 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 def add_molecule ( self , index : str , molecule : off . Molecule , attributes : Dict [ str , Any ], extras : Optional [ Dict [ str , Any ]] = None , keywords : Optional [ Dict [ str , Any ]] = None , ** kwargs , ) -> None : \"\"\" Add a molecule to the dataset under the given index with the passed cmiles. Parameters: index : str The molecule index that was generated by the factory. molecule : openforcefield.topology.Molecule The instance of the molecule which contains its conformer information. attributes : Dict[str, str] The attributes dictionary containing all of the relevant identifier tags for the molecule and extra meta information on the calculation. extras : Dict[str, Any], optional, default=None The extras that should be supplied into the qcportal.moldels.Molecule. keywords : Dict[str, Any], optional, default=None, Any extra keywords which are required for the calculation. Note: Each molecule in this basic dataset should have all of its conformers expanded out into separate entries. Thus here we take the general molecule index and increment it. \"\"\" try : data_entry = DatasetEntry ( off_molecule = molecule , index = index , attributes = attributes , extras = extras , keywords = keywords , ** kwargs , ) self . dataset [ index ] = data_entry except qcel . exceptions . ValidationError : # the molecule has some qcschema issue and should be removed self . filter_molecules ( molecules = molecule , component_name = \"QCSchemaIssues\" , component_description = { \"component_description\" : \"The molecule was removed as a valid QCSchema could not be made\" , \"component_name\" : \"QCSchemaIssues\" , }, component_provenance = self . provenance , ) Add a molecule to the dataset under the given index with the passed cmiles. Parameters Name Type Description Default index : str The molecule index that was generated by the factory. molecule : openforcefield.topology.Molecule The instance of the molecule which contains its conformer information. attributes : Dict[str, str] The attributes dictionary containing all of the relevant identifier tags for the molecule and extra meta information on the calculation. extras : Dict[str, Any], optional, default=None The extras that should be supplied into the qcportal.moldels.Molecule. keywords : Dict[str, Any], optional, default=None, Any extra keywords which are required for the calculation. Note Each molecule in this basic dataset should have all of its conformers expanded out into separate entries. Thus here we take the general molecule index and increment it.","title":"add_molecule()"},{"location":"datasets/#qcsubmit.datasets.BasicDataset.coverage_report","text":"Show source code in qcsubmit/datasets.py 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 def coverage_report ( self , forcefields : List [ str ]) -> Dict : \"\"\" Produce a coverage report of all of the parameters that are exercised by the molecules in the dataset. Parameters: forcefields: The name of the openforcefield force field which should be included in the coverage report. Returns: A dictionary for each of the force fields which break down which parameters are exercised by their parameter type. \"\"\" from openforcefield.typing.engines.smirnoff import ForceField from openforcefield.utils.structure import get_molecule_parameterIDs coverage = {} param_types = { \"a\" : \"Angles\" , \"b\" : \"Bonds\" , \"c\" : \"Constraints\" , \"t\" : \"ProperTorsions\" , \"i\" : \"ImproperTorsions\" , \"n\" : \"vdW\" , } if isinstance ( forcefields , str ): forcefields = [ forcefields ] for forcefield in forcefields : result = {} ff = ForceField ( forcefield ) parameters_by_molecule , parameters_by_id = get_molecule_parameterIDs ( list ( self . molecules ), ff ) # now create the the dict to store the ids used for param_id in parameters_by_id . keys (): result . setdefault ( param_types [ param_id [ 0 ]], []) . append ( param_id ) # now store the force field dict into the main result coverage [ forcefield ] = result return coverage Produce a coverage report of all of the parameters that are exercised by the molecules in the dataset. Parameters Name Type Description Default forcefields List[str] The name of the openforcefield force field which should be included in the coverage report. required Returns Type Description Dict A dictionary for each of the force fields which break down which parameters are exercised by their parameter type.","title":"coverage_report()"},{"location":"datasets/#qcsubmit.datasets.BasicDataset.export_dataset","text":"Show source code in qcsubmit/datasets.py 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 def export_dataset ( self , file_name : str ) -> None : \"\"\" Export the dataset to file so that it can be used to make another dataset quickly. Parameters: file_name: The name of the file the dataset should be wrote to. Note: The supported file types are: - `json` Raises: UnsupportedFiletypeError: If the requested file type is not supported. \"\"\" file_type = file_name . split ( \".\" )[ - 1 ] if file_type == \"json\" : with open ( file_name , \"w\" ) as output : output . write ( self . json ( indent = 2 )) else : raise UnsupportedFiletypeError ( f \"The requested file type { file_type } is not supported please use \" f \"json or yaml\" ) Export the dataset to file so that it can be used to make another dataset quickly. Parameters Name Type Description Default file_name str The name of the file the dataset should be wrote to. required Note The supported file types are: json Exceptions Type Description UnsupportedFiletypeError If the requested file type is not supported.","title":"export_dataset()"},{"location":"datasets/#qcsubmit.datasets.BasicDataset.filter_molecules","text":"Show source code in qcsubmit/datasets.py 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 def filter_molecules ( self , molecules : Union [ off . Molecule , List [ off . Molecule ]], component_name : str , component_description : Dict [ str , Any ], component_provenance : Dict [ str , str ], ) -> None : \"\"\" Filter a molecule or list of molecules by the component they failed. Parameters: molecules: A molecule or list of molecules to be filtered. component_description: The dictionary representation of the component that filtered this set of molecules. component_name: The name of the component. component_provenance: The dictionary representation of the component provenance. \"\"\" if isinstance ( molecules , off . Molecule ): # make into a list molecules = [ molecules ] if component_name in self . filtered_molecules : filter_mols = [ molecule . to_smiles ( isomeric = True , explicit_hydrogens = True ) for molecule in molecules ] self . filtered_molecules [ component_name ] . molecules . extend ( filter_mols ) else : filter_data = FilterEntry ( off_molecules = molecules , component_name = component_name , component_provenance = component_provenance , component_description = component_description , ) self . filtered_molecules [ filter_data . component_name ] = filter_data Filter a molecule or list of molecules by the component they failed. Parameters Name Type Description Default molecules: A molecule or list of molecules to be filtered. component_description: The dictionary representation of the component that filtered this set of molecules. component_name: The name of the component. component_provenance: The dictionary representation of the component provenance.","title":"filter_molecules()"},{"location":"datasets/#qcsubmit.datasets.BasicDataset.molecules_to_file","text":"Show source code in qcsubmit/datasets.py 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 def molecules_to_file ( self , file_name : str , file_type : str ) -> None : \"\"\" Write the molecules to the requested file type. Important: The supported file types are: - SMI - INCHI - INCKIKEY \"\"\" file_writers = { \"smi\" : self . _molecules_to_smiles , \"inchi\" : self . _molecules_to_inchi , \"inchikey\" : self . _molecules_to_inchikey , } try : # get the list of molecules molecules = file_writers [ file_type . lower ()]() with open ( file_name , \"w\" ) as output : for molecule in molecules : output . write ( f \" { molecule } \\n \" ) except KeyError : raise UnsupportedFiletypeError ( f \"The requested file type { file_type } is not supported, supported types are\" f \" { file_writers . keys () } .\" ) Write the molecules to the requested file type. Important The supported file types are: SMI INCHI INCKIKEY","title":"molecules_to_file()"},{"location":"datasets/#qcsubmit.datasets.BasicDataset.submit","text":"Show source code in qcsubmit/datasets.py 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 def submit ( self , client : Union [ str , ptl . FractalClient ], await_result : Optional [ bool ] = False , ) -> SingleResult : \"\"\" Submit the dataset to the chosen qcarchive address and finish or wait for the results and return the corresponding result class. Parameters: client : Union[str, qcportal.FractalClient] The name of the file containing the client information or an actual client instance. await_result : bool, optional, default=False If the user wants to wait for the calculation to finish before returning. Returns: The collection of the results which have completed. \"\"\" target_client = self . _activate_client ( client ) # work out if we are extending a collection try : collection = target_client . get_collection ( \"Dataset\" , self . dataset_name ) except KeyError : collection = ptl . collections . Dataset ( name = self . dataset_name , client = target_client , default_driver = self . driver , default_program = self . program , tagline = self . dataset_tagline , tags = self . dataset_tags , description = self . description , provenance = self . provenance , metadata = self . metadata , ) # store the keyword set into the collection kw = ptl . models . KeywordSet ( values = self . dict ( include = { \"maxiter\" , \"scf_properties\" }) ) try : # try and add the keywords if present then continue collection . add_keywords ( alias = self . spec_name , program = self . program , keyword = kw , default = True ) collection . save () except ( KeyError , AttributeError ): pass i = 0 # now add the molecules to the database, saving every 30 for speed for index , data in self . dataset . items (): # check if the index we have been supplied has a number tag already if so start from this tag index , tag = self . _clean_index ( index = index ) for j , molecule in enumerate ( data . initial_molecules ): name = index + f \"- { tag + j } \" try : collection . add_entry ( name = name , molecule = molecule ) i += 1 except KeyError : continue finally : if i % 30 == 0 : # save the added entries collection . save () # save the final dataset collection . save () # submit the calculations response = collection . compute ( method = self . method , basis = self . basis , keywords = self . spec_name , program = self . program , tag = self . compute_tag , priority = self . priority , ) collection . save () return response Submit the dataset to the chosen qcarchive address and finish or wait for the results and return the corresponding result class. Parameters Name Type Description Default client : Union[str, qcportal.FractalClient] The name of the file containing the client information or an actual client instance. await_result : bool, optional, default=False If the user wants to wait for the calculation to finish before returning. Returns Type Description SingleResult The collection of the results which have completed.","title":"submit()"},{"location":"datasets/#qcsubmit.datasets.ComponentResult","text":"Class to contain molecules after the execution of a workflow component this automatically applies de-duplication to the molecules. For example if a molecule is already in the molecules list it will not be added but any conformers will be kept and transferred. If a molecule in the molecules list is then filtered it will be removed from the molecules list.","title":"ComponentResult"},{"location":"datasets/#qcsubmit.datasets.ComponentResult.n_conformers","text":"Returns Type Description int The number of conformers stored in the molecules.","title":"n_conformers"},{"location":"datasets/#qcsubmit.datasets.ComponentResult.n_filtered","text":"Returns Type Description int The number of filtered molecules.","title":"n_filtered"},{"location":"datasets/#qcsubmit.datasets.ComponentResult.n_molecules","text":"Returns Type Description int The number of molecules saved in the result.","title":"n_molecules"},{"location":"datasets/#qcsubmit.datasets.ComponentResult.add_molecule","text":"Show source code in qcsubmit/datasets.py 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 def add_molecule ( self , molecule : off . Molecule ): \"\"\" Add a molecule to the molecule list after checking that it is not present already. If it is de-duplicate the record and condense the conformers. \"\"\" import numpy as np from simtk import unit if molecule in self . molecules : # we need to align the molecules and transfer the coords and properties mol_id = self . molecules . index ( molecule ) # get the mapping isomorphic , mapping = off . Molecule . are_isomorphic ( molecule , self . molecules [ mol_id ], return_atom_map = True ) assert isomorphic is True # transfer any torsion indexs for similar fragments if \"dihedrals\" in molecule . properties : # remap the dihedrals for dihedral , dihedral_range in molecule . properties [ \"dihedrals\" ] . items (): if len ( dihedral ) == 4 : mapped_dihedral = tuple ([ mapping [ i ] for i in dihedral ]) elif len ( dihedral ) == 2 : # this is a 2d dihedral mapped_dihedral = ( tuple ([ mapping [ i ] for i in dihedral [ 0 ]]), tuple ([ mapping [ i ] for i in dihedral [ 1 ]]), ) try : self . molecules [ mol_id ] . properties [ \"dihedrals\" ][ mapped_dihedral ] = dihedral_range except KeyError : self . molecules [ mol_id ] . properties [ \"dihedrals\" ] = { mapped_dihedral : dihedral_range } if molecule . n_conformers != 0 : # transfer the coordinates for conformer in molecule . conformers : new_conformer = np . zeros (( molecule . n_atoms , 3 )) for i in range ( molecule . n_atoms ): new_conformer [ i ] = conformer [ mapping [ i ]] . value_in_unit ( unit . angstrom ) new_conf = unit . Quantity ( value = new_conformer , unit = unit . angstrom ) # check if the conformer is already on the molecule for old_conformer in self . molecules [ mol_id ] . conformers : if old_conformer . tolist () == new_conf . tolist (): break else : self . molecules [ mol_id ] . add_conformer ( new_conformer * unit . angstrom ) else : # molecule already in list and coords not present so just return return else : self . molecules . append ( molecule ) Add a molecule to the molecule list after checking that it is not present already. If it is de-duplicate the record and condense the conformers.","title":"add_molecule()"},{"location":"datasets/#qcsubmit.datasets.ComponentResult.filter_molecule","text":"Show source code in qcsubmit/datasets.py 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 def filter_molecule ( self , molecule : off . Molecule ): \"\"\" Filter out a molecule that has not passed this workflow component. If the molecule is already in the pass list remove it and ensure it is only in the filtered list. \"\"\" try : self . molecules . remove ( molecule ) except ValueError : pass finally : if molecule not in self . filtered : self . filtered . append ( molecule ) else : return Filter out a molecule that has not passed this workflow component. If the molecule is already in the pass list remove it and ensure it is only in the filtered list.","title":"filter_molecule()"},{"location":"datasets/#qcsubmit.datasets.DatasetEntry","text":"A basic data class to construct the datasets which holds any information about the molecule and options used in the qcarchive calculation. Note extras are passed into the qcelemental.models.Molecule on creation. any extras that should passed to the calculation like extra constrains should be passed to keywords .","title":"DatasetEntry"},{"location":"datasets/#qcsubmit.datasets.FilterEntry","text":"A basic data class that contains information on components run in a workflow and the associated molecules which were removed by it.","title":"FilterEntry"},{"location":"datasets/#qcsubmit.datasets.OptimizationDataset","text":"An optimisation dataset class which handles submission of settings differently from the basic dataset, and creates optimization datasets in the public or local qcarcive instance.","title":"OptimizationDataset"},{"location":"datasets/#qcsubmit.datasets.OptimizationDataset.get_qc_spec","text":"Show source code in qcsubmit/datasets.py 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 def get_qc_spec ( self , keyword_id : str ) -> QCSpecification : \"\"\" Create the QC specification for the computation. Parameters: keyword_id: The string of the keyword set id number. Returns: The dictionary representation of the QC specification \"\"\" qc_spec = QCSpecification ( driver = self . driver , method = self . method , basis = self . basis , keywords = keyword_id , program = self . program , ) return qc_spec Create the QC specification for the computation. Parameters Name Type Description Default keyword_id str The string of the keyword set id number. required Returns Type Description QCSpecification The dictionary representation of the QC specification","title":"get_qc_spec()"},{"location":"datasets/#qcsubmit.datasets.OptimizationDataset.submit","text":"Show source code in qcsubmit/datasets.py 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 def submit ( self , client : Union [ str , ptl . FractalClient ], await_result : bool = False ) -> SingleResult : \"\"\" Submit the dataset to the chosen qcarchive address and finish or wait for the results and return the corresponding result class. Parameters: await_result: If the user wants to wait for the calculation to finish before returning. client: The name of the file containing the client information or the client instance. Returns: Either `None` if we are not waiting for the results or a BasicResult instance with all of the completed calculations. \"\"\" target_client = self . _activate_client ( client ) # work out if we are extending a collection try : collection = target_client . get_collection ( \"OptimizationDataset\" , self . dataset_name ) except KeyError : collection = ptl . collections . OptimizationDataset ( name = self . dataset_name , client = target_client , default_driver = self . driver , default_program = self . program , tagline = self . dataset_tagline , tags = self . dataset_tags , description = self . description , provenance = self . provenance , metadata = self . metadata , ) # store the keyword set into the collection kw_id = self . _add_keywords ( target_client ) # create the optimization specification opt_spec = self . optimization_procedure . get_optimzation_spec () # create the qc specification qc_spec = self . get_qc_spec ( keyword_id = kw_id ) collection . add_specification ( name = self . spec_name , optimization_spec = opt_spec , qc_spec = qc_spec , description = self . spec_description , overwrite = False , ) i = 0 # now add the molecules to the database, saving every 30 for speed for index , data in self . dataset . items (): # check if the index we have been supplied has a number tag already if so start from this tag index , tag = self . _clean_index ( index = index ) for j , molecule in enumerate ( data . initial_molecules ): name = index + f \"- { tag + j } \" try : collection . add_entry ( name = name , initial_molecule = molecule , attributes = data . attributes , additional_keywords = data . keywords , save = False , ) i += 1 except KeyError : continue finally : if i % 30 == 0 : # save the added entries collection . save () # save the added entries collection . save () # submit the calculations response = collection . compute ( specification = self . spec_name , tag = self . compute_tag , priority = self . priority ) return response Submit the dataset to the chosen qcarchive address and finish or wait for the results and return the corresponding result class. Parameters Name Type Description Default await_result bool If the user wants to wait for the calculation to finish before returning. False client Union[str, qcportal.client.FractalClient] The name of the file containing the client information or the client instance. required Returns Type Description SingleResult Either None if we are not waiting for the results or a BasicResult instance with all of the completed calculations.","title":"submit()"},{"location":"datasets/#qcsubmit.datasets.TorsiondriveDataset","text":"An torsiondrive dataset class which handles submission of settings differently from the basic dataset, and creates torsiondrive datasets in the public or local qcarcive instance. Important The dihedral_ranges for the whole dataset can be defined here or if different scan ranges are required on a case by case basis they can be defined for each torsion in a molecule separately in the properties attribute of the molecule. For example mol.properties['dihedral_range'] = (-165, 180)","title":"TorsiondriveDataset"},{"location":"datasets/#qcsubmit.datasets.TorsiondriveDataset.submit","text":"Show source code in qcsubmit/datasets.py 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 def submit ( self , client : Union [ str , ptl . FractalClient ], await_result : bool = False ) -> SingleResult : \"\"\" Submit the dataset to the chosen qcarchive address and finish or wait for the results and return the corresponding result class. Parameters: await_result: If the user wants to wait for the calculation to finish before returning. client: The name of the file containing the client information or the client instance. Returns: Either `None` if we are not waiting for the results or a BasicResult instance with all of the completed calculations. \"\"\" target_client = self . _activate_client ( client ) # work out if we are extending a collection try : collection = target_client . get_collection ( \"TorsionDriveDataset\" , self . dataset_name ) except KeyError : collection = ptl . collections . TorsionDriveDataset ( name = self . dataset_name , client = target_client , default_driver = self . driver , default_program = self . program , tagline = self . dataset_tagline , tags = self . dataset_tags , description = self . description , provenance = self . provenance , metadata = self . metadata , ) # store the keyword set into the collection kw_id = self . _add_keywords ( target_client ) # create the optimization specification opt_spec = self . optimization_procedure . get_optimzation_spec () # create the qc specification qc_spec = self . get_qc_spec ( keyword_id = kw_id ) collection . add_specification ( name = self . spec_name , optimization_spec = opt_spec , qc_spec = qc_spec , description = self . spec_description , overwrite = True , ) # start add the molecule to the dataset, multipule conformers/molecules can be used as the starting geometry for i , ( index , data ) in enumerate ( self . dataset . items ()): try : collection . add_entry ( name = index , initial_molecules = data . initial_molecules , dihedrals = data . dihedrals , grid_spacing = self . grid_spacings , energy_upper_limit = self . energy_upper_limit , attributes = data . attributes , energy_decrease_thresh = self . energy_decrease_thresh , dihedral_ranges = data . keywords . get ( \"dihedral_ranges\" , None ) or self . dihedral_ranges , ) except KeyError : continue finally : if i % 30 == 0 : collection . save () collection . save () # submit the calculations response = collection . compute ( specification = self . spec_name , tag = self . compute_tag , priority = self . priority ) return response Submit the dataset to the chosen qcarchive address and finish or wait for the results and return the corresponding result class. Parameters Name Type Description Default await_result bool If the user wants to wait for the calculation to finish before returning. False client Union[str, qcportal.client.FractalClient] The name of the file containing the client information or the client instance. required Returns Type Description SingleResult Either None if we are not waiting for the results or a BasicResult instance with all of the completed calculations.","title":"submit()"},{"location":"exceptions/","text":"CompoenentRequirementError \u00b6 The requested workflow componenet could not be added due to missing requirements. DatasetInputError \u00b6 The information entered into the dataset is not valid or missing so component. DriverError \u00b6 The requested driver is not valid. InvalidClientError \u00b6 The requested client address could not be contacted. InvalidWorkflowComponentError \u00b6 The workflow component is invalid. MissingWorkflowComponentError \u00b6 The requested workflow component could not be found. QCSubmitException \u00b6 Base QCSubmit exception, should always use the appropriate subclass of this exception. UnsupportedFiletypeError \u00b6 The file type requested is not supported.","title":"Exceptions"},{"location":"exceptions/#qcsubmit.exceptions.CompoenentRequirementError","text":"The requested workflow componenet could not be added due to missing requirements.","title":"CompoenentRequirementError"},{"location":"exceptions/#qcsubmit.exceptions.DatasetInputError","text":"The information entered into the dataset is not valid or missing so component.","title":"DatasetInputError"},{"location":"exceptions/#qcsubmit.exceptions.DriverError","text":"The requested driver is not valid.","title":"DriverError"},{"location":"exceptions/#qcsubmit.exceptions.InvalidClientError","text":"The requested client address could not be contacted.","title":"InvalidClientError"},{"location":"exceptions/#qcsubmit.exceptions.InvalidWorkflowComponentError","text":"The workflow component is invalid.","title":"InvalidWorkflowComponentError"},{"location":"exceptions/#qcsubmit.exceptions.MissingWorkflowComponentError","text":"The requested workflow component could not be found.","title":"MissingWorkflowComponentError"},{"location":"exceptions/#qcsubmit.exceptions.QCSubmitException","text":"Base QCSubmit exception, should always use the appropriate subclass of this exception.","title":"QCSubmitException"},{"location":"exceptions/#qcsubmit.exceptions.UnsupportedFiletypeError","text":"The file type requested is not supported.","title":"UnsupportedFiletypeError"},{"location":"factories/","text":"BasicDatasetFactory \u00b6 Basic dataset generator factory used to build work flows using workflow components before executing them to generate a dataset. The basic dataset is ideal for large collections of single point calculations using any of the energy, gradient or hessian drivers. The main metadata features here are concerned with the QM settings to be used which includes the driver. Attributes: method: The QM theory to use during dataset calculations. basis: The basis set to use during dataset calculations. program: The program which will be used during the calculations. maxiter: The maximum amount of SCF cycles allowed. driver: The driver that should be used in the calculation ie energy/gradient/hessian. scf_properties: A list of QM properties which should be calculated and collected during the driver calculation. client: The name of the client the data will be sent to for privet clusters this should be the file name where the data is stored. priority: The priority with which the dataset should be calculated. tag: The tag name which should be given to the collection. workflow: A dictionary which holds the workflow components to be executed in the set order. add_compute ( self , dataset_name , client , await_result = False ) \u00b6 Show source code in qcsubmit/factories.py 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 def add_compute ( self , dataset_name : str , client : Union [ str , FractalClient ], await_result : bool = False , ) -> None : \"\"\" A method that can add compute to an existing collection, this involves registering the QM settings and keywords and running the compute. Parameters: dataset_name: The name of the collection in the qcarchive instance that the compute should be added to. await_result: If the function should block until the calculations have finished. client: The name of the file containing the client information or the client instance. \"\"\" import qcportal as ptl if isinstance ( client , ptl . FractalClient ): target_client = client elif client == \"public\" : target_client = ptl . FractalClient () else : target_client = ptl . FractalClient . from_file ( client ) try : collection = target_client . get_collection ( \"Dataset\" , dataset_name ) except KeyError : raise KeyError ( f \"The collection: { dataset_name } could not be found, you can only add compute to existing\" f \"collections.\" ) kw = ptl . models . KeywordSet ( values = self . dict ( include = { \"maxiter\" , \"scf_properties\" }) ) try : # try add the keywords, if we get an error they have already been added. collection . add_keywords ( alias = self . spec_name , program = self . program , keyword = kw , default = False ) # save the keywords collection . save () except ( KeyError , AttributeError ): pass # submit the calculations response = collection . compute ( method = self . method , basis = self . basis , keywords = self . spec_name , program = self . program , tag = self . compute_tag , priority = self . priority , ) collection . save () return response A method that can add compute to an existing collection, this involves registering the QM settings and keywords and running the compute. Parameters Name Type Description Default dataset_name str The name of the collection in the qcarchive instance that the compute should be added to. required await_result bool If the function should block until the calculations have finished. False client Union[str, qcportal.client.FractalClient] The name of the file containing the client information or the client instance. required add_workflow_component ( self , components ) \u00b6 Show source code in qcsubmit/factories.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 def add_workflow_component ( self , components : Union [ List [ workflow_components . CustomWorkflowComponent ], workflow_components . CustomWorkflowComponent , ], ) -> None : \"\"\" Take the workflow components validate them then insert them into the workflow. Parameters: components: A list of or an individual qcsubmit.workflow_compoents.CustomWokflowComponent which are to be validated and added to the current workflow. Raises: InvalidWorkflowComponentError: If an invalid workflow component is attempted to be added to the workflow. \"\"\" if not isinstance ( components , list ): # we have one component make it into a list components = [ components ] for component in components : if isinstance ( component , workflow_components . CustomWorkflowComponent ): if not component . is_available (): raise CompoenentRequirementError ( f \"The component { component . component_name } could not be added to \" f \"the workflow due to missing requirements\" ) if component . component_name not in self . workflow . keys (): self . workflow [ component . component_name ] = component else : # we should increment the name and add it to the workflow if \"@\" in component . component_name : name , number = component . component_name . split ( \"@\" ) else : name , number = component . component_name , 0 # set the new name component . component_name = f \" { name } @ { int ( number ) + 1 } \" self . workflow [ component . component_name ] = component else : raise InvalidWorkflowComponentError ( f \"Component { component } rejected as it is not a sub \" f \"class of CustomWorkflowComponent.\" ) Take the workflow components validate them then insert them into the workflow. Parameters Name Type Description Default components Union[List[qcsubmit.workflow_components.base_component.CustomWorkflowComponent], qcsubmit.workflow_components.base_component.CustomWorkflowComponent] A list of or an individual qcsubmit.workflow_compoents.CustomWokflowComponent which are to be validated and added to the current workflow. required Exceptions Type Description InvalidWorkflowComponentError If an invalid workflow component is attempted to be added to the workflow. clear_workflow ( self ) \u00b6 Show source code in qcsubmit/factories.py 112 113 114 115 116 def clear_workflow ( self ) -> None : \"\"\" Reset the workflow to by empty. \"\"\" self . workflow = {} Reset the workflow to by empty. create_cmiles_metadata ( self , molecule ) \u00b6 Show source code in qcsubmit/factories.py 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 def create_cmiles_metadata ( self , molecule : off . Molecule ) -> Dict [ str , str ]: \"\"\" Create the Cmiles metadata for the molecule in this dataset. Parameters: molecule: The molecule for which the cmiles data will be generated. Returns: The Cmiles identifiers generated for the input molecule. Note: The Cmiles identifiers currently include: - `canonical_smiles` - `canonical_isomeric_smiles` - `canonical_explicit_hydrogen_smiles` - `canonical_isomeric_explicit_hydrogen_smiles` - `canonical_isomeric_explicit_hydrogen_mapped_smiles` - `molecular_formula` - `standard_inchi` - `inchi_key` \"\"\" cmiles = { \"canonical_smiles\" : molecule . to_smiles ( isomeric = False , explicit_hydrogens = False , mapped = False ), \"canonical_isomeric_smiles\" : molecule . to_smiles ( isomeric = True , explicit_hydrogens = False , mapped = False ), \"canonical_explicit_hydrogen_smiles\" : molecule . to_smiles ( isomeric = False , explicit_hydrogens = True , mapped = False ), \"canonical_isomeric_explicit_hydrogen_smiles\" : molecule . to_smiles ( isomeric = True , explicit_hydrogens = True , mapped = False ), \"canonical_isomeric_explicit_hydrogen_mapped_smiles\" : molecule . to_smiles ( isomeric = True , explicit_hydrogens = True , mapped = True ), \"molecular_formula\" : molecule . hill_formula , \"standard_inchi\" : molecule . to_inchi ( fixed_hydrogens = False ), \"inchi_key\" : molecule . to_inchikey ( fixed_hydrogens = False ), } return cmiles Create the Cmiles metadata for the molecule in this dataset. Parameters Name Type Description Default molecule Molecule The molecule for which the cmiles data will be generated. required Returns Type Description Dict[str, str] The Cmiles identifiers generated for the input molecule. Note The Cmiles identifiers currently include: canonical_smiles canonical_isomeric_smiles canonical_explicit_hydrogen_smiles canonical_isomeric_explicit_hydrogen_smiles canonical_isomeric_explicit_hydrogen_mapped_smiles molecular_formula standard_inchi inchi_key create_dataset ( self , dataset_name , molecules , description = None ) \u00b6 Show source code in qcsubmit/factories.py 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 def create_dataset ( self , dataset_name : str , molecules : Union [ str , List [ off . Molecule ], off . Molecule ], description : Optional [ str ] = None , ) -> BasicDataset : \"\"\" Process the input molecules through the given workflow then create and populate the dataset class which acts as a local representation for the collection in qcarchive and has the ability to submit its self to a local or public instance. Parameters: dataset_name: The name that will be given to the collection on submission to an archive instance. molecules: The list of molecules which should be processed by the workflow and added to the dataset, this can also be a file name which is to be unpacked by the openforcefield toolkit. description: A string describing the dataset. Example: How to make a dataset from a list of molecules ```python >>> from qcsubmit.factories import BasicDatasetFactory >>> from qcsubmit import workflow_components >>> from openforcefield.topology import Molecule >>> factory = BasicDatasetFactory() >>> gen = workflow_components.StandardConformerGenerator() >>> gen.clear_exsiting = True >>> gen.max_conformers = 1 >>> factory.add_workflow_component(gen) >>> smiles = ['C', 'CC', 'CCO'] >>> mols = [Molecule.from_smiles(smile) for smile in smiles] >>> dataset = factory.create_dataset(dataset_name='My collection', molecules=mols) ``` Returns: A [DataSet][qcsubmit.datasets.DataSet] instance populated with the molecules that have passed through the workflow. Important: The dataset once created does not allow mutation. \"\"\" # TODO set up a logging system to report the components # create an initial component result workflow_molecules = self . _create_initial_component_result ( molecules = molecules ) # create the dataset # first we need to instance the dataset and assign the metadata object_meta = self . dict ( exclude = { \"workflow\" }) # the only data missing is the collection name so add it here. object_meta [ \"dataset_name\" ] = dataset_name object_meta [ \"description\" ] = description object_meta [ \"metadata\" ] = { \"date\" : str ( datetime . datetime . now () . date ())} object_meta [ \"provenance\" ] = self . provenance () dataset = self . _dataset_type . parse_obj ( object_meta ) # if the workflow has components run it if self . workflow : for component in self . workflow . values (): workflow_molecules = component . apply ( molecules = workflow_molecules . molecules ) dataset . filter_molecules ( molecules = workflow_molecules . filtered , component_name = workflow_molecules . component_name , component_description = workflow_molecules . component_description , component_provenance = workflow_molecules . component_provenance , ) # now add the molecules to the correct attributes for molecule in workflow_molecules . molecules : # order the molecule order_mol = molecule . canonical_order_atoms () attributes = self . create_cmiles_metadata ( molecule = order_mol ) attributes [ \"provenance\" ] = self . provenance () # if we are using MM we should put the cmiles in the extras extras = molecule . properties . get ( \"extras\" , {}) if self . program in self . _mm_programs : extras [ \"canonical_isomeric_explicit_hydrogen_mapped_smiles\" ] = attributes [ \"canonical_isomeric_explicit_hydrogen_mapped_smiles\" ] keywords = molecule . properties . get ( \"keywords\" , None ) # now submit the molecule dataset . add_molecule ( index = self . create_index ( molecule = order_mol ), molecule = order_mol , attributes = attributes , extras = extras if bool ( extras ) else None , keywords = keywords , ) return dataset Process the input molecules through the given workflow then create and populate the dataset class which acts as a local representation for the collection in qcarchive and has the ability to submit its self to a local or public instance. Parameters Name Type Description Default dataset_name str The name that will be given to the collection on submission to an archive instance. required molecules Union[str, List[openforcefield.topology.molecule.Molecule], openforcefield.topology.molecule.Molecule] The list of molecules which should be processed by the workflow and added to the dataset, this can also be a file name which is to be unpacked by the openforcefield toolkit. required description Optional[str] A string describing the dataset. None Example How to make a dataset from a list of molecules >>> from qcsubmit.factories import BasicDatasetFactory >>> from qcsubmit import workflow_components >>> from openforcefield.topology import Molecule >>> factory = BasicDatasetFactory () >>> gen = workflow_components . StandardConformerGenerator () >>> gen . clear_exsiting = True >>> gen . max_conformers = 1 >>> factory . add_workflow_component ( gen ) >>> smiles = [ 'C' , 'CC' , 'CCO' ] >>> mols = [ Molecule . from_smiles ( smile ) for smile in smiles ] >>> dataset = factory . create_dataset ( dataset_name = 'My collection' , molecules = mols ) Returns Type Description BasicDataset A [DataSet][qcsubmit.datasets.DataSet] instance populated with the molecules that have passed through the workflow. Important The dataset once created does not allow mutation. create_index ( self , molecule ) \u00b6 Show source code in qcsubmit/factories.py 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 def create_index ( self , molecule : off . Molecule ) -> str : \"\"\" Create an index for the current molecule. Parameters: molecule: The molecule for which the dataset index will be generated. Returns: The canonical isomeric smiles for the molecule which is used as the dataset index. Important: Each dataset can have a different indexing system depending on the data, in this basic dataset each conformer of a molecule is expanded into its own entry separately indexed entry. This is handled by the dataset however so we just generate a general index for the molecule before adding to the dataset. \"\"\" index = molecule . to_smiles ( isomeric = True , explicit_hydrogens = False , mapped = False ) return index Create an index for the current molecule. Parameters Name Type Description Default molecule Molecule The molecule for which the dataset index will be generated. required Returns Type Description str The canonical isomeric smiles for the molecule which is used as the dataset index. Important Each dataset can have a different indexing system depending on the data, in this basic dataset each conformer of a molecule is expanded into its own entry separately indexed entry. This is handled by the dataset however so we just generate a general index for the molecule before adding to the dataset. export_settings ( self , file_name ) \u00b6 Show source code in qcsubmit/factories.py 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 def export_settings ( self , file_name : str ) -> None : \"\"\" Export the current model to file this will include the workflow as well along with each components settings. Parameters: file_name: The name of the file the settings and workflow should be exported to. Raises: UnsupportedFiletypeError: When the file type requested is not supported. \"\"\" file_type = self . _get_file_type ( file_name = file_name ) # try and get the file writer try : writer = self . _file_writers [ file_type ] with open ( file_name , \"w\" ) as output : if file_type == \"json\" : writer ( self . dict (), output , indent = 2 ) else : data = self . dict ( exclude = { \"driver\" }) data [ \"driver\" ] = self . driver . value writer ( data , output ) except KeyError : raise UnsupportedFiletypeError ( f \"The requested file type { file_type } is not supported, \" f \"currently we can write to { self . _file_writers } .\" ) Export the current model to file this will include the workflow as well along with each components settings. Parameters Name Type Description Default file_name str The name of the file the settings and workflow should be exported to. required Exceptions Type Description UnsupportedFiletypeError When the file type requested is not supported. export_workflow ( self , file_name ) \u00b6 Show source code in qcsubmit/factories.py 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 def export_workflow ( self , file_name : str ) -> None : \"\"\" Export the workflow components and their settings to file so that they can be loaded latter. Parameters: file_name: The name of the file the workflow should be exported to. Raises: UnsupportedFiletypeError: If the file type is not supported. \"\"\" file_type = self . _get_file_type ( file_name = file_name ) # try and get the file writer workflow = self . dict ()[ \"workflow\" ] try : writer = self . _file_writers [ file_type ] with open ( file_name , \"w\" ) as output : if file_type == \"json\" : writer ( workflow , output , indent = 2 ) else : writer ( workflow , output ) except KeyError : raise UnsupportedFiletypeError ( f \"The requested file type { file_type } is not supported, \" f \"currently we can write to { self . _file_writers } .\" ) Export the workflow components and their settings to file so that they can be loaded latter. Parameters Name Type Description Default file_name str The name of the file the workflow should be exported to. required Exceptions Type Description UnsupportedFiletypeError If the file type is not supported. get_workflow_component ( self , component_name ) \u00b6 Show source code in qcsubmit/factories.py 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 def get_workflow_component ( self , component_name : str ) -> workflow_components . CustomWorkflowComponent : \"\"\" Find the workflow component by its component_name attribute. Parameters: component_name: The name of the component to be gathered from the workflow. Returns: The instance of the requested component from the workflow. Raises: MissingWorkflowComponentError: If the component could not be found by its component name in the workflow. \"\"\" component = self . workflow . get ( component_name , None ) if component is None : raise MissingWorkflowComponentError ( f \"The requested component { component_name } \" f \"was not registered into the workflow.\" ) return component Find the workflow component by its component_name attribute. Parameters Name Type Description Default component_name str The name of the component to be gathered from the workflow. required Returns Type Description CustomWorkflowComponent The instance of the requested component from the workflow. Exceptions Type Description MissingWorkflowComponentError If the component could not be found by its component name in the workflow. import_settings ( self , settings , clear_workflow = True ) \u00b6 Show source code in qcsubmit/factories.py 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 def import_settings ( self , settings : Union [ str , Dict ], clear_workflow : bool = True ) -> None : \"\"\" Import settings and workflow from a file. Parameters: settings: The name of the file the settings should be extracted from or the reference to a settings dictionary. clear_workflow: If the current workflow should be extended or replaced. \"\"\" if isinstance ( settings , str ): data = self . _read_file ( settings ) # take the workflow out and import the settings workflow = data . pop ( \"workflow\" ) elif isinstance ( settings , dict ): workflow = settings . pop ( \"workflow\" ) data = settings else : raise RuntimeError ( f \"The input type could not be converted into a settings dictionary.\" ) # now set the factory meta settings for key , value in data . items (): if hasattr ( self , key ): setattr ( self , key , value ) else : continue # now we want to add the workflow back in self . import_workflow ( workflow = workflow , clear_existing = clear_workflow ) Import settings and workflow from a file. Parameters Name Type Description Default settings Union[str, Dict] The name of the file the settings should be extracted from or the reference to a settings dictionary. required clear_workflow bool If the current workflow should be extended or replaced. True import_workflow ( self , workflow , clear_existing = True ) \u00b6 Show source code in qcsubmit/factories.py 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 def import_workflow ( self , workflow : Union [ str , Dict ], clear_existing : bool = True ) -> None : \"\"\" Instance the workflow from a workflow object or from an input file. Parameters: workflow: The name of the file the workflow should be created from or a workflow dictionary. clear_existing: If the current workflow should be deleted and replaced or extended. \"\"\" if clear_existing : self . clear_workflow () if isinstance ( workflow , str ): workflow = self . _read_file ( workflow ) if isinstance ( workflow , dict ): # this should be a workflow dict that we can just load # if this is from the settings file make sure to unpack the dict first. workflow = workflow . get ( \"workflow\" , workflow ) # load in the workflow for key , value in workflow . items (): # check if this is not the first instance of the component if \"@\" in key : name = key . split ( \"@\" )[ 0 ] else : name = key component = getattr ( workflow_components , name , None ) if component is not None : self . add_workflow_component ( component . parse_obj ( value )) Instance the workflow from a workflow object or from an input file. Parameters Name Type Description Default workflow Union[str, Dict] The name of the file the workflow should be created from or a workflow dictionary. required clear_existing bool If the current workflow should be deleted and replaced or extended. True provenance ( self ) \u00b6 Show source code in qcsubmit/factories.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 def provenance ( self ) -> Dict [ str , str ]: \"\"\" Create the provenance of qcsubmit that created that molecule input data. Returns: A dict of the provenance information. Important: We can not check which toolkit was used to generate the Cmiles data be we know that openeye will always be used first when available. \"\"\" import openforcefield import qcsubmit provenance = { \"qcsubmit\" : qcsubmit . __version__ , \"openforcefield\" : openforcefield . __version__ , } return provenance Create the provenance of qcsubmit that created that molecule input data. Returns Type Description Dict[str, str] A dict of the provenance information. Important We can not check which toolkit was used to generate the Cmiles data be we know that openeye will always be used first when available. remove_workflow_component ( self , component_name ) \u00b6 Show source code in qcsubmit/factories.py 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 def remove_workflow_component ( self , component_name : str ) -> None : \"\"\" Find and remove the component via its component_name attribute. Parameters: component_name: The name of the component to be gathered from the workflow. Raises: MissingWorkflowComponentError: If the component could not be found by its component name in the workflow. \"\"\" try : del self . workflow [ component_name ] except KeyError : raise MissingWorkflowComponentError ( f \"The requested component { component_name } \" f \"could not be removed as it was not registered.\" ) Find and remove the component via its component_name attribute. Parameters Name Type Description Default component_name str The name of the component to be gathered from the workflow. required Exceptions Type Description MissingWorkflowComponentError If the component could not be found by its component name in the workflow. OptimizationDatasetFactory \u00b6 This factory produces OptimisationDatasets which include settings associated with geometric which is used to run the optimisation. add_compute ( self , dataset_name , client , await_result = False ) \u00b6 Show source code in qcsubmit/factories.py 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 def add_compute ( self , dataset_name : str , client : Union [ str , FractalClient ], await_result : bool = False , ) -> None : \"\"\" Add compute to an exsiting collection of molecules. Parameters: dataset_name: client: await_result: \"\"\" raise NotImplementedError () Add compute to an exsiting collection of molecules. Parameters Name Type Description Default dataset_name str required client Union[str, qcportal.client.FractalClient] required await_result bool False TorsiondriveDatasetFactory \u00b6 This factory produces TorsiondriveDatasets which include settings associated with geometric which is used to run the optimisation. add_compute ( self , dataset_name , client , await_result = False ) \u00b6 Show source code in qcsubmit/factories.py 945 946 947 948 949 950 951 952 953 954 955 def add_compute ( self , dataset_name : str , client : Union [ str , FractalClient ], await_result : bool = False , ) -> None : \"\"\" \"\"\" raise NotImplementedError () create_dataset ( self , dataset_name , molecules , description = None ) \u00b6 Show source code in qcsubmit/factories.py 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 def create_dataset ( self , dataset_name : str , molecules : Union [ str , List [ off . Molecule ], off . Molecule ], description : str = None , ) -> TorsiondriveDataset : \"\"\" Process the input molecules through the given workflow then create and populate the torsiondrive dataset class which acts as a local representation for the collection in qcarchive and has the ability to submit its self to a local or public instance. Note: The torsiondrive dataset allows for multiple starting geometries. Important: Any molecules with linear torsions identified for torsion driving will be removed and failed from the workflow. Important: If fragmentation is used each molecule in the dataset will have the torsion indexes already set else indexes are generated for each rotatable torsion in the molecule. Parameters: dataset_name: The name that will be given to the collection on submission to an archive instance. molecules: The list of molecules which should be processed by the workflow and added to the dataset, this can also be a file name which is to be unpacked by the openforcefield toolkit. Returns: A [DataSet][qcsubmit.datasets.TorsiondriveDataset] instance populated with the molecules that have passed through the workflow. \"\"\" # create the initial component result workflow_molecules = self . _create_initial_component_result ( molecules = molecules ) # cach any linear torsions here linear_torsions = { \"component_name\" : \"LinearTorsionRemoval\" , \"component_description\" : { \"component_description\" : \"Remove any molecules with a linear torsions selected to drive.\" , }, \"component_provenance\" : self . provenance (), \"molecules\" : [], } # first we need to instance the dataset and assign the metadata object_meta = self . dict ( exclude = { \"workflow\" }) # the only data missing is the collection name so add it here. object_meta [ \"dataset_name\" ] = dataset_name object_meta [ \"description\" ] = description object_meta [ \"metadata\" ] = { \"date\" : str ( datetime . datetime . now () . date ())} object_meta [ \"provenance\" ] = self . provenance () dataset = self . _dataset_type ( ** object_meta ) # if the workflow has components run it if self . workflow : for component_name , component in self . workflow . items (): workflow_molecules = component . apply ( molecules = workflow_molecules . molecules ) dataset . filter_molecules ( molecules = workflow_molecules . filtered , component_name = workflow_molecules . component_name , component_description = workflow_molecules . component_description , component_provenance = workflow_molecules . component_provenance , ) # now add the molecules to the correct attributes for molecule in workflow_molecules . molecules : # check if there are any linear torsions in the molecule linear_bonds = self . _detect_linear_torsions ( molecule ) # check for extras and keywords extras = molecule . properties . get ( \"extras\" , {}) keywords = molecule . properties . get ( \"keywords\" , {}) # check if the molecule has an atom map or dihedrals defined if \"atom_map\" in molecule . properties : # we need to check the map and convert it to use the dihedrals method if len ( molecule . properties [ \"atom_map\" ]) == 4 : # the map is for the correct amount of atoms atom_map = molecule . properties . pop ( \"atom_map\" ) molecule . properties [ \"dihedrals\" ] = { tuple ( atom_map . keys ()): None } # make the general attributes attributes = self . create_cmiles_metadata ( molecule = molecule ) # now check for the dihedrals if \"dihedrals\" in molecule . properties : for dihedral , dihedral_range in molecule . properties [ \"dihedrals\" ] . items (): # check for a 2d torsion scan if len ( dihedral ) == 8 : # create the dihedrals list of tuples dihedrals = [ tuple ( dihedral [ 0 : 4 ]), tuple ( dihedral [ 4 : 8 ])] elif len ( dihedral ) == 4 : dihedrals = [ dihedral ] else : continue for torsion in dihedrals : if ( torsion [ 1 : 3 ] in linear_bonds or torsion [ 2 : 0 : - 1 ] in linear_bonds ): linear_torsions [ \"molecules\" ] . append ( molecule ) break else : # create the index molecule . properties [ \"atom_map\" ] = dict ( ( atom , i ) for i , atom in enumerate ( dihedral ) ) index = self . create_index ( molecule = molecule ) del molecule . properties [ \"atom_map\" ] keywords [ \"dihedral_ranges\" ] = dihedral_range dataset . add_molecule ( index = index , molecule = molecule , attributes = attributes , dihedrals = dihedrals , keywords = keywords , extras = extras , ) else : # the molecule has not had its atoms identified yet so process them here # order the molecule order_mol = molecule . canonical_order_atoms () rotatble_bonds = order_mol . find_rotatable_bonds () attributes = self . create_cmiles_metadata ( molecule = order_mol ) for bond in rotatble_bonds : # create a torsion to hold as fixed using non-hydrogen atoms torsion_index = self . _get_torsion_string ( bond ) order_mol . properties [ \"atom_map\" ] = dict ( ( atom , index ) for index , atom in enumerate ( torsion_index ) ) dataset . add_molecule ( index = self . create_index ( molecule = order_mol ), molecule = order_mol , attributes = attributes , dihedrals = [ torsion_index ], extras = extras , ) # now we need to filter the linear molecules dataset . filter_molecules ( ** linear_torsions ) return dataset Process the input molecules through the given workflow then create and populate the torsiondrive dataset class which acts as a local representation for the collection in qcarchive and has the ability to submit its self to a local or public instance. Note The torsiondrive dataset allows for multiple starting geometries. Important Any molecules with linear torsions identified for torsion driving will be removed and failed from the workflow. Important If fragmentation is used each molecule in the dataset will have the torsion indexes already set else indexes are generated for each rotatable torsion in the molecule. Parameters Name Type Description Default dataset_name str The name that will be given to the collection on submission to an archive instance. required molecules Union[str, List[openforcefield.topology.molecule.Molecule], openforcefield.topology.molecule.Molecule] The list of molecules which should be processed by the workflow and added to the dataset, this can also be a file name which is to be unpacked by the openforcefield toolkit. required Returns Type Description TorsiondriveDataset A DataSet instance populated with the molecules that have passed through the workflow. create_index ( self , molecule ) \u00b6 Show source code in qcsubmit/factories.py 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 def create_index ( self , molecule : off . Molecule ) -> str : \"\"\" Create a specific torsion index for the molecule, this will use the atom map on the molecule. Parameters: molecule: The molecule for which the dataset index will be generated. Returns: The canonical mapped isomeric smiles, where the mapped indices are on the atoms in the torsion. Important: This dataset uses a non-standard indexing with 4 atom mapped indices representing the atoms in the torsion to be rotated. \"\"\" assert \"atom_map\" in molecule . properties . keys () assert ( len ( molecule . properties [ \"atom_map\" ]) == 4 or len ( molecule . properties [ \"atom_map\" ]) == 8 ) index = molecule . to_smiles ( isomeric = True , explicit_hydrogens = True , mapped = True ) return index Create a specific torsion index for the molecule, this will use the atom map on the molecule. Parameters Name Type Description Default molecule Molecule The molecule for which the dataset index will be generated. required Returns Type Description str The canonical mapped isomeric smiles, where the mapped indices are on the atoms in the torsion. Important This dataset uses a non-standard indexing with 4 atom mapped indices representing the atoms in the torsion to be rotated.","title":"Factories"},{"location":"factories/#qcsubmit.factories.BasicDatasetFactory","text":"Basic dataset generator factory used to build work flows using workflow components before executing them to generate a dataset. The basic dataset is ideal for large collections of single point calculations using any of the energy, gradient or hessian drivers. The main metadata features here are concerned with the QM settings to be used which includes the driver. Attributes: method: The QM theory to use during dataset calculations. basis: The basis set to use during dataset calculations. program: The program which will be used during the calculations. maxiter: The maximum amount of SCF cycles allowed. driver: The driver that should be used in the calculation ie energy/gradient/hessian. scf_properties: A list of QM properties which should be calculated and collected during the driver calculation. client: The name of the client the data will be sent to for privet clusters this should be the file name where the data is stored. priority: The priority with which the dataset should be calculated. tag: The tag name which should be given to the collection. workflow: A dictionary which holds the workflow components to be executed in the set order.","title":"BasicDatasetFactory"},{"location":"factories/#qcsubmit.factories.BasicDatasetFactory.add_compute","text":"Show source code in qcsubmit/factories.py 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 def add_compute ( self , dataset_name : str , client : Union [ str , FractalClient ], await_result : bool = False , ) -> None : \"\"\" A method that can add compute to an existing collection, this involves registering the QM settings and keywords and running the compute. Parameters: dataset_name: The name of the collection in the qcarchive instance that the compute should be added to. await_result: If the function should block until the calculations have finished. client: The name of the file containing the client information or the client instance. \"\"\" import qcportal as ptl if isinstance ( client , ptl . FractalClient ): target_client = client elif client == \"public\" : target_client = ptl . FractalClient () else : target_client = ptl . FractalClient . from_file ( client ) try : collection = target_client . get_collection ( \"Dataset\" , dataset_name ) except KeyError : raise KeyError ( f \"The collection: { dataset_name } could not be found, you can only add compute to existing\" f \"collections.\" ) kw = ptl . models . KeywordSet ( values = self . dict ( include = { \"maxiter\" , \"scf_properties\" }) ) try : # try add the keywords, if we get an error they have already been added. collection . add_keywords ( alias = self . spec_name , program = self . program , keyword = kw , default = False ) # save the keywords collection . save () except ( KeyError , AttributeError ): pass # submit the calculations response = collection . compute ( method = self . method , basis = self . basis , keywords = self . spec_name , program = self . program , tag = self . compute_tag , priority = self . priority , ) collection . save () return response A method that can add compute to an existing collection, this involves registering the QM settings and keywords and running the compute. Parameters Name Type Description Default dataset_name str The name of the collection in the qcarchive instance that the compute should be added to. required await_result bool If the function should block until the calculations have finished. False client Union[str, qcportal.client.FractalClient] The name of the file containing the client information or the client instance. required","title":"add_compute()"},{"location":"factories/#qcsubmit.factories.BasicDatasetFactory.add_workflow_component","text":"Show source code in qcsubmit/factories.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 def add_workflow_component ( self , components : Union [ List [ workflow_components . CustomWorkflowComponent ], workflow_components . CustomWorkflowComponent , ], ) -> None : \"\"\" Take the workflow components validate them then insert them into the workflow. Parameters: components: A list of or an individual qcsubmit.workflow_compoents.CustomWokflowComponent which are to be validated and added to the current workflow. Raises: InvalidWorkflowComponentError: If an invalid workflow component is attempted to be added to the workflow. \"\"\" if not isinstance ( components , list ): # we have one component make it into a list components = [ components ] for component in components : if isinstance ( component , workflow_components . CustomWorkflowComponent ): if not component . is_available (): raise CompoenentRequirementError ( f \"The component { component . component_name } could not be added to \" f \"the workflow due to missing requirements\" ) if component . component_name not in self . workflow . keys (): self . workflow [ component . component_name ] = component else : # we should increment the name and add it to the workflow if \"@\" in component . component_name : name , number = component . component_name . split ( \"@\" ) else : name , number = component . component_name , 0 # set the new name component . component_name = f \" { name } @ { int ( number ) + 1 } \" self . workflow [ component . component_name ] = component else : raise InvalidWorkflowComponentError ( f \"Component { component } rejected as it is not a sub \" f \"class of CustomWorkflowComponent.\" ) Take the workflow components validate them then insert them into the workflow. Parameters Name Type Description Default components Union[List[qcsubmit.workflow_components.base_component.CustomWorkflowComponent], qcsubmit.workflow_components.base_component.CustomWorkflowComponent] A list of or an individual qcsubmit.workflow_compoents.CustomWokflowComponent which are to be validated and added to the current workflow. required Exceptions Type Description InvalidWorkflowComponentError If an invalid workflow component is attempted to be added to the workflow.","title":"add_workflow_component()"},{"location":"factories/#qcsubmit.factories.BasicDatasetFactory.clear_workflow","text":"Show source code in qcsubmit/factories.py 112 113 114 115 116 def clear_workflow ( self ) -> None : \"\"\" Reset the workflow to by empty. \"\"\" self . workflow = {} Reset the workflow to by empty.","title":"clear_workflow()"},{"location":"factories/#qcsubmit.factories.BasicDatasetFactory.create_cmiles_metadata","text":"Show source code in qcsubmit/factories.py 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 def create_cmiles_metadata ( self , molecule : off . Molecule ) -> Dict [ str , str ]: \"\"\" Create the Cmiles metadata for the molecule in this dataset. Parameters: molecule: The molecule for which the cmiles data will be generated. Returns: The Cmiles identifiers generated for the input molecule. Note: The Cmiles identifiers currently include: - `canonical_smiles` - `canonical_isomeric_smiles` - `canonical_explicit_hydrogen_smiles` - `canonical_isomeric_explicit_hydrogen_smiles` - `canonical_isomeric_explicit_hydrogen_mapped_smiles` - `molecular_formula` - `standard_inchi` - `inchi_key` \"\"\" cmiles = { \"canonical_smiles\" : molecule . to_smiles ( isomeric = False , explicit_hydrogens = False , mapped = False ), \"canonical_isomeric_smiles\" : molecule . to_smiles ( isomeric = True , explicit_hydrogens = False , mapped = False ), \"canonical_explicit_hydrogen_smiles\" : molecule . to_smiles ( isomeric = False , explicit_hydrogens = True , mapped = False ), \"canonical_isomeric_explicit_hydrogen_smiles\" : molecule . to_smiles ( isomeric = True , explicit_hydrogens = True , mapped = False ), \"canonical_isomeric_explicit_hydrogen_mapped_smiles\" : molecule . to_smiles ( isomeric = True , explicit_hydrogens = True , mapped = True ), \"molecular_formula\" : molecule . hill_formula , \"standard_inchi\" : molecule . to_inchi ( fixed_hydrogens = False ), \"inchi_key\" : molecule . to_inchikey ( fixed_hydrogens = False ), } return cmiles Create the Cmiles metadata for the molecule in this dataset. Parameters Name Type Description Default molecule Molecule The molecule for which the cmiles data will be generated. required Returns Type Description Dict[str, str] The Cmiles identifiers generated for the input molecule. Note The Cmiles identifiers currently include: canonical_smiles canonical_isomeric_smiles canonical_explicit_hydrogen_smiles canonical_isomeric_explicit_hydrogen_smiles canonical_isomeric_explicit_hydrogen_mapped_smiles molecular_formula standard_inchi inchi_key","title":"create_cmiles_metadata()"},{"location":"factories/#qcsubmit.factories.BasicDatasetFactory.create_dataset","text":"Show source code in qcsubmit/factories.py 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 def create_dataset ( self , dataset_name : str , molecules : Union [ str , List [ off . Molecule ], off . Molecule ], description : Optional [ str ] = None , ) -> BasicDataset : \"\"\" Process the input molecules through the given workflow then create and populate the dataset class which acts as a local representation for the collection in qcarchive and has the ability to submit its self to a local or public instance. Parameters: dataset_name: The name that will be given to the collection on submission to an archive instance. molecules: The list of molecules which should be processed by the workflow and added to the dataset, this can also be a file name which is to be unpacked by the openforcefield toolkit. description: A string describing the dataset. Example: How to make a dataset from a list of molecules ```python >>> from qcsubmit.factories import BasicDatasetFactory >>> from qcsubmit import workflow_components >>> from openforcefield.topology import Molecule >>> factory = BasicDatasetFactory() >>> gen = workflow_components.StandardConformerGenerator() >>> gen.clear_exsiting = True >>> gen.max_conformers = 1 >>> factory.add_workflow_component(gen) >>> smiles = ['C', 'CC', 'CCO'] >>> mols = [Molecule.from_smiles(smile) for smile in smiles] >>> dataset = factory.create_dataset(dataset_name='My collection', molecules=mols) ``` Returns: A [DataSet][qcsubmit.datasets.DataSet] instance populated with the molecules that have passed through the workflow. Important: The dataset once created does not allow mutation. \"\"\" # TODO set up a logging system to report the components # create an initial component result workflow_molecules = self . _create_initial_component_result ( molecules = molecules ) # create the dataset # first we need to instance the dataset and assign the metadata object_meta = self . dict ( exclude = { \"workflow\" }) # the only data missing is the collection name so add it here. object_meta [ \"dataset_name\" ] = dataset_name object_meta [ \"description\" ] = description object_meta [ \"metadata\" ] = { \"date\" : str ( datetime . datetime . now () . date ())} object_meta [ \"provenance\" ] = self . provenance () dataset = self . _dataset_type . parse_obj ( object_meta ) # if the workflow has components run it if self . workflow : for component in self . workflow . values (): workflow_molecules = component . apply ( molecules = workflow_molecules . molecules ) dataset . filter_molecules ( molecules = workflow_molecules . filtered , component_name = workflow_molecules . component_name , component_description = workflow_molecules . component_description , component_provenance = workflow_molecules . component_provenance , ) # now add the molecules to the correct attributes for molecule in workflow_molecules . molecules : # order the molecule order_mol = molecule . canonical_order_atoms () attributes = self . create_cmiles_metadata ( molecule = order_mol ) attributes [ \"provenance\" ] = self . provenance () # if we are using MM we should put the cmiles in the extras extras = molecule . properties . get ( \"extras\" , {}) if self . program in self . _mm_programs : extras [ \"canonical_isomeric_explicit_hydrogen_mapped_smiles\" ] = attributes [ \"canonical_isomeric_explicit_hydrogen_mapped_smiles\" ] keywords = molecule . properties . get ( \"keywords\" , None ) # now submit the molecule dataset . add_molecule ( index = self . create_index ( molecule = order_mol ), molecule = order_mol , attributes = attributes , extras = extras if bool ( extras ) else None , keywords = keywords , ) return dataset Process the input molecules through the given workflow then create and populate the dataset class which acts as a local representation for the collection in qcarchive and has the ability to submit its self to a local or public instance. Parameters Name Type Description Default dataset_name str The name that will be given to the collection on submission to an archive instance. required molecules Union[str, List[openforcefield.topology.molecule.Molecule], openforcefield.topology.molecule.Molecule] The list of molecules which should be processed by the workflow and added to the dataset, this can also be a file name which is to be unpacked by the openforcefield toolkit. required description Optional[str] A string describing the dataset. None Example How to make a dataset from a list of molecules >>> from qcsubmit.factories import BasicDatasetFactory >>> from qcsubmit import workflow_components >>> from openforcefield.topology import Molecule >>> factory = BasicDatasetFactory () >>> gen = workflow_components . StandardConformerGenerator () >>> gen . clear_exsiting = True >>> gen . max_conformers = 1 >>> factory . add_workflow_component ( gen ) >>> smiles = [ 'C' , 'CC' , 'CCO' ] >>> mols = [ Molecule . from_smiles ( smile ) for smile in smiles ] >>> dataset = factory . create_dataset ( dataset_name = 'My collection' , molecules = mols ) Returns Type Description BasicDataset A [DataSet][qcsubmit.datasets.DataSet] instance populated with the molecules that have passed through the workflow. Important The dataset once created does not allow mutation.","title":"create_dataset()"},{"location":"factories/#qcsubmit.factories.BasicDatasetFactory.create_index","text":"Show source code in qcsubmit/factories.py 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 def create_index ( self , molecule : off . Molecule ) -> str : \"\"\" Create an index for the current molecule. Parameters: molecule: The molecule for which the dataset index will be generated. Returns: The canonical isomeric smiles for the molecule which is used as the dataset index. Important: Each dataset can have a different indexing system depending on the data, in this basic dataset each conformer of a molecule is expanded into its own entry separately indexed entry. This is handled by the dataset however so we just generate a general index for the molecule before adding to the dataset. \"\"\" index = molecule . to_smiles ( isomeric = True , explicit_hydrogens = False , mapped = False ) return index Create an index for the current molecule. Parameters Name Type Description Default molecule Molecule The molecule for which the dataset index will be generated. required Returns Type Description str The canonical isomeric smiles for the molecule which is used as the dataset index. Important Each dataset can have a different indexing system depending on the data, in this basic dataset each conformer of a molecule is expanded into its own entry separately indexed entry. This is handled by the dataset however so we just generate a general index for the molecule before adding to the dataset.","title":"create_index()"},{"location":"factories/#qcsubmit.factories.BasicDatasetFactory.export_settings","text":"Show source code in qcsubmit/factories.py 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 def export_settings ( self , file_name : str ) -> None : \"\"\" Export the current model to file this will include the workflow as well along with each components settings. Parameters: file_name: The name of the file the settings and workflow should be exported to. Raises: UnsupportedFiletypeError: When the file type requested is not supported. \"\"\" file_type = self . _get_file_type ( file_name = file_name ) # try and get the file writer try : writer = self . _file_writers [ file_type ] with open ( file_name , \"w\" ) as output : if file_type == \"json\" : writer ( self . dict (), output , indent = 2 ) else : data = self . dict ( exclude = { \"driver\" }) data [ \"driver\" ] = self . driver . value writer ( data , output ) except KeyError : raise UnsupportedFiletypeError ( f \"The requested file type { file_type } is not supported, \" f \"currently we can write to { self . _file_writers } .\" ) Export the current model to file this will include the workflow as well along with each components settings. Parameters Name Type Description Default file_name str The name of the file the settings and workflow should be exported to. required Exceptions Type Description UnsupportedFiletypeError When the file type requested is not supported.","title":"export_settings()"},{"location":"factories/#qcsubmit.factories.BasicDatasetFactory.export_workflow","text":"Show source code in qcsubmit/factories.py 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 def export_workflow ( self , file_name : str ) -> None : \"\"\" Export the workflow components and their settings to file so that they can be loaded latter. Parameters: file_name: The name of the file the workflow should be exported to. Raises: UnsupportedFiletypeError: If the file type is not supported. \"\"\" file_type = self . _get_file_type ( file_name = file_name ) # try and get the file writer workflow = self . dict ()[ \"workflow\" ] try : writer = self . _file_writers [ file_type ] with open ( file_name , \"w\" ) as output : if file_type == \"json\" : writer ( workflow , output , indent = 2 ) else : writer ( workflow , output ) except KeyError : raise UnsupportedFiletypeError ( f \"The requested file type { file_type } is not supported, \" f \"currently we can write to { self . _file_writers } .\" ) Export the workflow components and their settings to file so that they can be loaded latter. Parameters Name Type Description Default file_name str The name of the file the workflow should be exported to. required Exceptions Type Description UnsupportedFiletypeError If the file type is not supported.","title":"export_workflow()"},{"location":"factories/#qcsubmit.factories.BasicDatasetFactory.get_workflow_component","text":"Show source code in qcsubmit/factories.py 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 def get_workflow_component ( self , component_name : str ) -> workflow_components . CustomWorkflowComponent : \"\"\" Find the workflow component by its component_name attribute. Parameters: component_name: The name of the component to be gathered from the workflow. Returns: The instance of the requested component from the workflow. Raises: MissingWorkflowComponentError: If the component could not be found by its component name in the workflow. \"\"\" component = self . workflow . get ( component_name , None ) if component is None : raise MissingWorkflowComponentError ( f \"The requested component { component_name } \" f \"was not registered into the workflow.\" ) return component Find the workflow component by its component_name attribute. Parameters Name Type Description Default component_name str The name of the component to be gathered from the workflow. required Returns Type Description CustomWorkflowComponent The instance of the requested component from the workflow. Exceptions Type Description MissingWorkflowComponentError If the component could not be found by its component name in the workflow.","title":"get_workflow_component()"},{"location":"factories/#qcsubmit.factories.BasicDatasetFactory.import_settings","text":"Show source code in qcsubmit/factories.py 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 def import_settings ( self , settings : Union [ str , Dict ], clear_workflow : bool = True ) -> None : \"\"\" Import settings and workflow from a file. Parameters: settings: The name of the file the settings should be extracted from or the reference to a settings dictionary. clear_workflow: If the current workflow should be extended or replaced. \"\"\" if isinstance ( settings , str ): data = self . _read_file ( settings ) # take the workflow out and import the settings workflow = data . pop ( \"workflow\" ) elif isinstance ( settings , dict ): workflow = settings . pop ( \"workflow\" ) data = settings else : raise RuntimeError ( f \"The input type could not be converted into a settings dictionary.\" ) # now set the factory meta settings for key , value in data . items (): if hasattr ( self , key ): setattr ( self , key , value ) else : continue # now we want to add the workflow back in self . import_workflow ( workflow = workflow , clear_existing = clear_workflow ) Import settings and workflow from a file. Parameters Name Type Description Default settings Union[str, Dict] The name of the file the settings should be extracted from or the reference to a settings dictionary. required clear_workflow bool If the current workflow should be extended or replaced. True","title":"import_settings()"},{"location":"factories/#qcsubmit.factories.BasicDatasetFactory.import_workflow","text":"Show source code in qcsubmit/factories.py 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 def import_workflow ( self , workflow : Union [ str , Dict ], clear_existing : bool = True ) -> None : \"\"\" Instance the workflow from a workflow object or from an input file. Parameters: workflow: The name of the file the workflow should be created from or a workflow dictionary. clear_existing: If the current workflow should be deleted and replaced or extended. \"\"\" if clear_existing : self . clear_workflow () if isinstance ( workflow , str ): workflow = self . _read_file ( workflow ) if isinstance ( workflow , dict ): # this should be a workflow dict that we can just load # if this is from the settings file make sure to unpack the dict first. workflow = workflow . get ( \"workflow\" , workflow ) # load in the workflow for key , value in workflow . items (): # check if this is not the first instance of the component if \"@\" in key : name = key . split ( \"@\" )[ 0 ] else : name = key component = getattr ( workflow_components , name , None ) if component is not None : self . add_workflow_component ( component . parse_obj ( value )) Instance the workflow from a workflow object or from an input file. Parameters Name Type Description Default workflow Union[str, Dict] The name of the file the workflow should be created from or a workflow dictionary. required clear_existing bool If the current workflow should be deleted and replaced or extended. True","title":"import_workflow()"},{"location":"factories/#qcsubmit.factories.BasicDatasetFactory.provenance","text":"Show source code in qcsubmit/factories.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 def provenance ( self ) -> Dict [ str , str ]: \"\"\" Create the provenance of qcsubmit that created that molecule input data. Returns: A dict of the provenance information. Important: We can not check which toolkit was used to generate the Cmiles data be we know that openeye will always be used first when available. \"\"\" import openforcefield import qcsubmit provenance = { \"qcsubmit\" : qcsubmit . __version__ , \"openforcefield\" : openforcefield . __version__ , } return provenance Create the provenance of qcsubmit that created that molecule input data. Returns Type Description Dict[str, str] A dict of the provenance information. Important We can not check which toolkit was used to generate the Cmiles data be we know that openeye will always be used first when available.","title":"provenance()"},{"location":"factories/#qcsubmit.factories.BasicDatasetFactory.remove_workflow_component","text":"Show source code in qcsubmit/factories.py 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 def remove_workflow_component ( self , component_name : str ) -> None : \"\"\" Find and remove the component via its component_name attribute. Parameters: component_name: The name of the component to be gathered from the workflow. Raises: MissingWorkflowComponentError: If the component could not be found by its component name in the workflow. \"\"\" try : del self . workflow [ component_name ] except KeyError : raise MissingWorkflowComponentError ( f \"The requested component { component_name } \" f \"could not be removed as it was not registered.\" ) Find and remove the component via its component_name attribute. Parameters Name Type Description Default component_name str The name of the component to be gathered from the workflow. required Exceptions Type Description MissingWorkflowComponentError If the component could not be found by its component name in the workflow.","title":"remove_workflow_component()"},{"location":"factories/#qcsubmit.factories.OptimizationDatasetFactory","text":"This factory produces OptimisationDatasets which include settings associated with geometric which is used to run the optimisation.","title":"OptimizationDatasetFactory"},{"location":"factories/#qcsubmit.factories.OptimizationDatasetFactory.add_compute","text":"Show source code in qcsubmit/factories.py 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 def add_compute ( self , dataset_name : str , client : Union [ str , FractalClient ], await_result : bool = False , ) -> None : \"\"\" Add compute to an exsiting collection of molecules. Parameters: dataset_name: client: await_result: \"\"\" raise NotImplementedError () Add compute to an exsiting collection of molecules. Parameters Name Type Description Default dataset_name str required client Union[str, qcportal.client.FractalClient] required await_result bool False","title":"add_compute()"},{"location":"factories/#qcsubmit.factories.TorsiondriveDatasetFactory","text":"This factory produces TorsiondriveDatasets which include settings associated with geometric which is used to run the optimisation.","title":"TorsiondriveDatasetFactory"},{"location":"factories/#qcsubmit.factories.TorsiondriveDatasetFactory.add_compute","text":"Show source code in qcsubmit/factories.py 945 946 947 948 949 950 951 952 953 954 955 def add_compute ( self , dataset_name : str , client : Union [ str , FractalClient ], await_result : bool = False , ) -> None : \"\"\" \"\"\" raise NotImplementedError ()","title":"add_compute()"},{"location":"factories/#qcsubmit.factories.TorsiondriveDatasetFactory.create_dataset","text":"Show source code in qcsubmit/factories.py 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 def create_dataset ( self , dataset_name : str , molecules : Union [ str , List [ off . Molecule ], off . Molecule ], description : str = None , ) -> TorsiondriveDataset : \"\"\" Process the input molecules through the given workflow then create and populate the torsiondrive dataset class which acts as a local representation for the collection in qcarchive and has the ability to submit its self to a local or public instance. Note: The torsiondrive dataset allows for multiple starting geometries. Important: Any molecules with linear torsions identified for torsion driving will be removed and failed from the workflow. Important: If fragmentation is used each molecule in the dataset will have the torsion indexes already set else indexes are generated for each rotatable torsion in the molecule. Parameters: dataset_name: The name that will be given to the collection on submission to an archive instance. molecules: The list of molecules which should be processed by the workflow and added to the dataset, this can also be a file name which is to be unpacked by the openforcefield toolkit. Returns: A [DataSet][qcsubmit.datasets.TorsiondriveDataset] instance populated with the molecules that have passed through the workflow. \"\"\" # create the initial component result workflow_molecules = self . _create_initial_component_result ( molecules = molecules ) # cach any linear torsions here linear_torsions = { \"component_name\" : \"LinearTorsionRemoval\" , \"component_description\" : { \"component_description\" : \"Remove any molecules with a linear torsions selected to drive.\" , }, \"component_provenance\" : self . provenance (), \"molecules\" : [], } # first we need to instance the dataset and assign the metadata object_meta = self . dict ( exclude = { \"workflow\" }) # the only data missing is the collection name so add it here. object_meta [ \"dataset_name\" ] = dataset_name object_meta [ \"description\" ] = description object_meta [ \"metadata\" ] = { \"date\" : str ( datetime . datetime . now () . date ())} object_meta [ \"provenance\" ] = self . provenance () dataset = self . _dataset_type ( ** object_meta ) # if the workflow has components run it if self . workflow : for component_name , component in self . workflow . items (): workflow_molecules = component . apply ( molecules = workflow_molecules . molecules ) dataset . filter_molecules ( molecules = workflow_molecules . filtered , component_name = workflow_molecules . component_name , component_description = workflow_molecules . component_description , component_provenance = workflow_molecules . component_provenance , ) # now add the molecules to the correct attributes for molecule in workflow_molecules . molecules : # check if there are any linear torsions in the molecule linear_bonds = self . _detect_linear_torsions ( molecule ) # check for extras and keywords extras = molecule . properties . get ( \"extras\" , {}) keywords = molecule . properties . get ( \"keywords\" , {}) # check if the molecule has an atom map or dihedrals defined if \"atom_map\" in molecule . properties : # we need to check the map and convert it to use the dihedrals method if len ( molecule . properties [ \"atom_map\" ]) == 4 : # the map is for the correct amount of atoms atom_map = molecule . properties . pop ( \"atom_map\" ) molecule . properties [ \"dihedrals\" ] = { tuple ( atom_map . keys ()): None } # make the general attributes attributes = self . create_cmiles_metadata ( molecule = molecule ) # now check for the dihedrals if \"dihedrals\" in molecule . properties : for dihedral , dihedral_range in molecule . properties [ \"dihedrals\" ] . items (): # check for a 2d torsion scan if len ( dihedral ) == 8 : # create the dihedrals list of tuples dihedrals = [ tuple ( dihedral [ 0 : 4 ]), tuple ( dihedral [ 4 : 8 ])] elif len ( dihedral ) == 4 : dihedrals = [ dihedral ] else : continue for torsion in dihedrals : if ( torsion [ 1 : 3 ] in linear_bonds or torsion [ 2 : 0 : - 1 ] in linear_bonds ): linear_torsions [ \"molecules\" ] . append ( molecule ) break else : # create the index molecule . properties [ \"atom_map\" ] = dict ( ( atom , i ) for i , atom in enumerate ( dihedral ) ) index = self . create_index ( molecule = molecule ) del molecule . properties [ \"atom_map\" ] keywords [ \"dihedral_ranges\" ] = dihedral_range dataset . add_molecule ( index = index , molecule = molecule , attributes = attributes , dihedrals = dihedrals , keywords = keywords , extras = extras , ) else : # the molecule has not had its atoms identified yet so process them here # order the molecule order_mol = molecule . canonical_order_atoms () rotatble_bonds = order_mol . find_rotatable_bonds () attributes = self . create_cmiles_metadata ( molecule = order_mol ) for bond in rotatble_bonds : # create a torsion to hold as fixed using non-hydrogen atoms torsion_index = self . _get_torsion_string ( bond ) order_mol . properties [ \"atom_map\" ] = dict ( ( atom , index ) for index , atom in enumerate ( torsion_index ) ) dataset . add_molecule ( index = self . create_index ( molecule = order_mol ), molecule = order_mol , attributes = attributes , dihedrals = [ torsion_index ], extras = extras , ) # now we need to filter the linear molecules dataset . filter_molecules ( ** linear_torsions ) return dataset Process the input molecules through the given workflow then create and populate the torsiondrive dataset class which acts as a local representation for the collection in qcarchive and has the ability to submit its self to a local or public instance. Note The torsiondrive dataset allows for multiple starting geometries. Important Any molecules with linear torsions identified for torsion driving will be removed and failed from the workflow. Important If fragmentation is used each molecule in the dataset will have the torsion indexes already set else indexes are generated for each rotatable torsion in the molecule. Parameters Name Type Description Default dataset_name str The name that will be given to the collection on submission to an archive instance. required molecules Union[str, List[openforcefield.topology.molecule.Molecule], openforcefield.topology.molecule.Molecule] The list of molecules which should be processed by the workflow and added to the dataset, this can also be a file name which is to be unpacked by the openforcefield toolkit. required Returns Type Description TorsiondriveDataset A DataSet instance populated with the molecules that have passed through the workflow.","title":"create_dataset()"},{"location":"factories/#qcsubmit.factories.TorsiondriveDatasetFactory.create_index","text":"Show source code in qcsubmit/factories.py 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 def create_index ( self , molecule : off . Molecule ) -> str : \"\"\" Create a specific torsion index for the molecule, this will use the atom map on the molecule. Parameters: molecule: The molecule for which the dataset index will be generated. Returns: The canonical mapped isomeric smiles, where the mapped indices are on the atoms in the torsion. Important: This dataset uses a non-standard indexing with 4 atom mapped indices representing the atoms in the torsion to be rotated. \"\"\" assert \"atom_map\" in molecule . properties . keys () assert ( len ( molecule . properties [ \"atom_map\" ]) == 4 or len ( molecule . properties [ \"atom_map\" ]) == 8 ) index = molecule . to_smiles ( isomeric = True , explicit_hydrogens = True , mapped = True ) return index Create a specific torsion index for the molecule, this will use the atom map on the molecule. Parameters Name Type Description Default molecule Molecule The molecule for which the dataset index will be generated. required Returns Type Description str The canonical mapped isomeric smiles, where the mapped indices are on the atoms in the torsion. Important This dataset uses a non-standard indexing with 4 atom mapped indices representing the atoms in the torsion to be rotated.","title":"create_index()"},{"location":"filters/","text":"File containing the filters workflow components. CoverageFilter \u00b6 Filters molecules based on the requested forcefield coverage. Important The ids supplied to the respective group are the ids that are allowed, if None is passed all ids are allowed. Atributes: allowed_ids: The list of parameter ids that we want to actively pass the filter. filtered_ids: The list of parameter ids that we want to actively filter out and fail the filter. Note If a molecule has any id in the allowed_ids and not in the filtered ids it is passed. Any molecule with a parameter in both sets is failed. Important A value of None in a list will let all molecules through. apply ( self , molecules ) \u00b6 Show source code in workflow_components/filters.py 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 def apply ( self , molecules : List [ Molecule ]) -> ComponentResult : \"\"\" Apply the filter to the list of molecules to remove any molecules typed by an id that is not allowed, i.e. not included in the allowed list. Parameters: molecules: The list of molecules the component should be applied on. Returns: A [ComponentResult][qcsubmit.datasets.ComponentResult] instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result. \"\"\" # pass all of the molecules then filter ones that have elements that are not allowed result = self . _create_result () # build a molecule mapping molecule_mapping = dict ( ( molecule . to_smiles (), molecule ) for molecule in molecules ) for molecule in molecules : result . add_molecule ( molecule ) # the forcefield we are testing against forcefield = ForceField ( self . forcefield ) parameters_by_molecule , parameters_by_ID = get_molecule_parameterIDs ( molecules , forcefield ) # loop through the tags if self . filtered_ids is not None : for filtered_id in self . filtered_ids : try : filtered = parameters_by_ID . pop ( filtered_id ) for molecule in filtered : self . fail_molecule ( molecule_mapping [ molecule ], result ) except KeyError : continue return result Apply the filter to the list of molecules to remove any molecules typed by an id that is not allowed, i.e. not included in the allowed list. Parameters Name Type Description Default molecules List[openforcefield.topology.molecule.Molecule] The list of molecules the component should be applied on. required Returns Type Description ComponentResult A ComponentResult instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result. provenance ( self ) \u00b6 Show source code in workflow_components/filters.py 282 283 284 285 286 287 288 289 290 291 292 293 294 def provenance ( self ) -> Dict : \"\"\" Generate version information for all of the software used during the running of this component. Returns: A dictionary of all of the software used in the component along wither their version numbers. \"\"\" import openforcefields provenance = super () . provenance () provenance [ \"oopenforcefields\" ] = openforcefields . __version__ return provenance Generate version information for all of the software used during the running of this component. Returns Type Description Dict A dictionary of all of the software used in the component along wither their version numbers. ElementFilter \u00b6 Filter the molecules based on a list of allowed elements. Attributes: component_name: The name of component. component_description: A short desciption of the component. component_fail_message: The message logged when a molecule fails this component. allowed_elements: A list of atomic symbols or atomic numbers which are allowed passed the filter. Note The allowed_elements attribute can take a list of either symbols or atomic numbers and will resolve them to a common internal format as required. Example Using atomic symbols or atomic numbers in components. >>> from qcsubmit import workflow_components >>> efil = workflow_components . ElementFilter () # set the allowed elements to H,C,N,O >>> efil . allowed_elements = [ 'H' , 'C' , 'N' , 'O' ] >>> efil . allowed_elements = [ 1 , 6 , 7 , 8 ] apply ( self , molecules ) \u00b6 Show source code in workflow_components/filters.py 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 def apply ( self , molecules : List [ Molecule ]) -> ComponentResult : \"\"\" The common entry point of all workflow components which applies the workflow component to the given list of molecules. Parameters: molecules: The list of molecules the component should be applied on. Returns: A [ComponentResult][qcsubmit.datasets.ComponentResult] instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result. \"\"\" from simtk.openmm.app import Element result = self . _create_result () # First lets convert the allowed_elements list to ints as this is what is stored in the atom object _allowed_elements = [ Element . getBySymbol ( ele ) . atomic_number if isinstance ( ele , str ) else ele for ele in self . allowed_elements ] # now apply the filter for molecule in molecules : for atom in molecule . atoms : if atom . atomic_number not in _allowed_elements : self . fail_molecule ( molecule = molecule , component_result = result ) break else : result . add_molecule ( molecule ) return result The common entry point of all workflow components which applies the workflow component to the given list of molecules. Parameters Name Type Description Default molecules List[openforcefield.topology.molecule.Molecule] The list of molecules the component should be applied on. required Returns Type Description ComponentResult A ComponentResult instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result. check_allowed_elements ( element ) (classmethod) \u00b6 Show source code in workflow_components/filters.py 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 @validator ( \"allowed_elements\" , each_item = True ) def check_allowed_elements ( cls , element : Union [ str , int ]) -> Union [ str , int ]: \"\"\" Check that each item can be cast to a valid element. Parameters: element: The element that should be checked. Raises: ValueError: If the element number or symbol passed could not be converted into a valid element. \"\"\" from simtk.openmm.app import Element if isinstance ( element , int ): return element else : try : e = Element . getBySymbol ( element ) return element except KeyError : raise KeyError ( f \"An element could not be determined from symbol { element } , please eneter symbols only.\" ) Check that each item can be cast to a valid element. Parameters Name Type Description Default element Union[str, int] The element that should be checked. required Exceptions Type Description ValueError If the element number or symbol passed could not be converted into a valid element. provenance ( self ) \u00b6 Show source code in workflow_components/filters.py 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 def provenance ( self ) -> Dict : \"\"\" Generate version information for all of the software used during the running of this component. Returns: A dictionary of all of the software used in the component along wither their version numbers. Note: The element class in OpenMM is used to match the elements so the OpenMM version is given. \"\"\" from simtk import openmm provenance = super () . provenance () provenance [ \"openmm_elements\" ] = openmm . __version__ return provenance Generate version information for all of the software used during the running of this component. Returns Type Description Dict A dictionary of all of the software used in the component along wither their version numbers. Note The element class in OpenMM is used to match the elements so the OpenMM version is given. MolecularWeightFilter \u00b6 Filters molecules based on the minimum and maximum allowed molecular weights. Attributes: fields.component_name: The name of component. fields.component_description: A short description of the component. fields.component_fail_message: The message logged when a molecule fails this component. fields.minimum_weight: The minimum allowed molecular weight of a molecule. fields.maximum_weight: The maximum allowed molecular weight of a molecule. apply ( self , molecules ) \u00b6 Show source code in workflow_components/filters.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 def apply ( self , molecules : List [ Molecule ]) -> ComponentResult : \"\"\" The common entry point of all workflow components which applies the workflow component to the given list of molecules. Parameters: molecules: The list of molecules the component should be applied on. Returns: A [ComponentResult][qcsubmit.datasets.ComponentResult] instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result. [qcsubmit.datasets.ComponentResult] \"\"\" from simtk import unit result = self . _create_result () for molecule in molecules : total_weight = sum ( [ atom . element . mass . value_in_unit ( unit . daltons ) for atom in molecule . atoms ] ) if self . minimum_weight < total_weight < self . maximum_weight : result . add_molecule ( molecule ) else : self . fail_molecule ( molecule = molecule , component_result = result ) return result The common entry point of all workflow components which applies the workflow component to the given list of molecules. Parameters Name Type Description Default molecules List[openforcefield.topology.molecule.Molecule] The list of molecules the component should be applied on. required Returns Type Description ComponentResult A ComponentResult instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result. qcsubmit.datasets.ComponentResult provenance ( self ) \u00b6 Show source code in workflow_components/filters.py 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 def provenance ( self ) -> Dict : \"\"\" Generate version information for all of the software used during the running of this component. Returns: A dictionary of all of the software used in the component along wither their version numbers. Important: The simtk unit module has no version information so the version of OpenMM is given instead. \"\"\" from simtk import openmm provenance = super () . provenance () provenance [ \"openmm_units\" ] = openmm . __version__ return provenance Generate version information for all of the software used during the running of this component. Returns Type Description Dict A dictionary of all of the software used in the component along wither their version numbers. Important The simtk unit module has no version information so the version of OpenMM is given instead. RotorFilter \u00b6 Filters molecules based on the maximum allowed number of rotatable bonds. Note Rotatable bonds are non terminal torsions found using the find_rotatable_bonds method of the openforcefield.topology.Molecule class. apply ( self , molecules ) \u00b6 Show source code in workflow_components/filters.py 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 def apply ( self , molecules : List [ Molecule ]) -> ComponentResult : \"\"\" Apply the filter to the list of molecules to remove any molecules with more rotors then the maximum allowed number. Parameters: molecules: The list of molecules the component should be applied on. Returns: A [ComponentResult][qcsubmit.datasets.ComponentResult] instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result. \"\"\" # create the return result = self . _create_result () # run the the molecules and calculate the number of rotatable bonds for molecule in molecules : if len ( molecule . find_rotatable_bonds ()) > self . maximum_rotors : self . fail_molecule ( molecule = molecule , component_result = result ) else : result . add_molecule ( molecule ) return result Apply the filter to the list of molecules to remove any molecules with more rotors then the maximum allowed number. Parameters Name Type Description Default molecules List[openforcefield.topology.molecule.Molecule] The list of molecules the component should be applied on. required Returns Type Description ComponentResult A ComponentResult instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result.","title":"Filters"},{"location":"filters/#qcsubmit.workflow_components.filters.CoverageFilter","text":"Filters molecules based on the requested forcefield coverage. Important The ids supplied to the respective group are the ids that are allowed, if None is passed all ids are allowed. Atributes: allowed_ids: The list of parameter ids that we want to actively pass the filter. filtered_ids: The list of parameter ids that we want to actively filter out and fail the filter. Note If a molecule has any id in the allowed_ids and not in the filtered ids it is passed. Any molecule with a parameter in both sets is failed. Important A value of None in a list will let all molecules through.","title":"CoverageFilter"},{"location":"filters/#qcsubmit.workflow_components.filters.CoverageFilter.apply","text":"Show source code in workflow_components/filters.py 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 def apply ( self , molecules : List [ Molecule ]) -> ComponentResult : \"\"\" Apply the filter to the list of molecules to remove any molecules typed by an id that is not allowed, i.e. not included in the allowed list. Parameters: molecules: The list of molecules the component should be applied on. Returns: A [ComponentResult][qcsubmit.datasets.ComponentResult] instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result. \"\"\" # pass all of the molecules then filter ones that have elements that are not allowed result = self . _create_result () # build a molecule mapping molecule_mapping = dict ( ( molecule . to_smiles (), molecule ) for molecule in molecules ) for molecule in molecules : result . add_molecule ( molecule ) # the forcefield we are testing against forcefield = ForceField ( self . forcefield ) parameters_by_molecule , parameters_by_ID = get_molecule_parameterIDs ( molecules , forcefield ) # loop through the tags if self . filtered_ids is not None : for filtered_id in self . filtered_ids : try : filtered = parameters_by_ID . pop ( filtered_id ) for molecule in filtered : self . fail_molecule ( molecule_mapping [ molecule ], result ) except KeyError : continue return result Apply the filter to the list of molecules to remove any molecules typed by an id that is not allowed, i.e. not included in the allowed list. Parameters Name Type Description Default molecules List[openforcefield.topology.molecule.Molecule] The list of molecules the component should be applied on. required Returns Type Description ComponentResult A ComponentResult instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result.","title":"apply()"},{"location":"filters/#qcsubmit.workflow_components.filters.CoverageFilter.provenance","text":"Show source code in workflow_components/filters.py 282 283 284 285 286 287 288 289 290 291 292 293 294 def provenance ( self ) -> Dict : \"\"\" Generate version information for all of the software used during the running of this component. Returns: A dictionary of all of the software used in the component along wither their version numbers. \"\"\" import openforcefields provenance = super () . provenance () provenance [ \"oopenforcefields\" ] = openforcefields . __version__ return provenance Generate version information for all of the software used during the running of this component. Returns Type Description Dict A dictionary of all of the software used in the component along wither their version numbers.","title":"provenance()"},{"location":"filters/#qcsubmit.workflow_components.filters.ElementFilter","text":"Filter the molecules based on a list of allowed elements. Attributes: component_name: The name of component. component_description: A short desciption of the component. component_fail_message: The message logged when a molecule fails this component. allowed_elements: A list of atomic symbols or atomic numbers which are allowed passed the filter. Note The allowed_elements attribute can take a list of either symbols or atomic numbers and will resolve them to a common internal format as required. Example Using atomic symbols or atomic numbers in components. >>> from qcsubmit import workflow_components >>> efil = workflow_components . ElementFilter () # set the allowed elements to H,C,N,O >>> efil . allowed_elements = [ 'H' , 'C' , 'N' , 'O' ] >>> efil . allowed_elements = [ 1 , 6 , 7 , 8 ]","title":"ElementFilter"},{"location":"filters/#qcsubmit.workflow_components.filters.ElementFilter.apply","text":"Show source code in workflow_components/filters.py 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 def apply ( self , molecules : List [ Molecule ]) -> ComponentResult : \"\"\" The common entry point of all workflow components which applies the workflow component to the given list of molecules. Parameters: molecules: The list of molecules the component should be applied on. Returns: A [ComponentResult][qcsubmit.datasets.ComponentResult] instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result. \"\"\" from simtk.openmm.app import Element result = self . _create_result () # First lets convert the allowed_elements list to ints as this is what is stored in the atom object _allowed_elements = [ Element . getBySymbol ( ele ) . atomic_number if isinstance ( ele , str ) else ele for ele in self . allowed_elements ] # now apply the filter for molecule in molecules : for atom in molecule . atoms : if atom . atomic_number not in _allowed_elements : self . fail_molecule ( molecule = molecule , component_result = result ) break else : result . add_molecule ( molecule ) return result The common entry point of all workflow components which applies the workflow component to the given list of molecules. Parameters Name Type Description Default molecules List[openforcefield.topology.molecule.Molecule] The list of molecules the component should be applied on. required Returns Type Description ComponentResult A ComponentResult instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result.","title":"apply()"},{"location":"filters/#qcsubmit.workflow_components.filters.ElementFilter.check_allowed_elements","text":"Show source code in workflow_components/filters.py 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 @validator ( \"allowed_elements\" , each_item = True ) def check_allowed_elements ( cls , element : Union [ str , int ]) -> Union [ str , int ]: \"\"\" Check that each item can be cast to a valid element. Parameters: element: The element that should be checked. Raises: ValueError: If the element number or symbol passed could not be converted into a valid element. \"\"\" from simtk.openmm.app import Element if isinstance ( element , int ): return element else : try : e = Element . getBySymbol ( element ) return element except KeyError : raise KeyError ( f \"An element could not be determined from symbol { element } , please eneter symbols only.\" ) Check that each item can be cast to a valid element. Parameters Name Type Description Default element Union[str, int] The element that should be checked. required Exceptions Type Description ValueError If the element number or symbol passed could not be converted into a valid element.","title":"check_allowed_elements()"},{"location":"filters/#qcsubmit.workflow_components.filters.ElementFilter.provenance","text":"Show source code in workflow_components/filters.py 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 def provenance ( self ) -> Dict : \"\"\" Generate version information for all of the software used during the running of this component. Returns: A dictionary of all of the software used in the component along wither their version numbers. Note: The element class in OpenMM is used to match the elements so the OpenMM version is given. \"\"\" from simtk import openmm provenance = super () . provenance () provenance [ \"openmm_elements\" ] = openmm . __version__ return provenance Generate version information for all of the software used during the running of this component. Returns Type Description Dict A dictionary of all of the software used in the component along wither their version numbers. Note The element class in OpenMM is used to match the elements so the OpenMM version is given.","title":"provenance()"},{"location":"filters/#qcsubmit.workflow_components.filters.MolecularWeightFilter","text":"Filters molecules based on the minimum and maximum allowed molecular weights. Attributes: fields.component_name: The name of component. fields.component_description: A short description of the component. fields.component_fail_message: The message logged when a molecule fails this component. fields.minimum_weight: The minimum allowed molecular weight of a molecule. fields.maximum_weight: The maximum allowed molecular weight of a molecule.","title":"MolecularWeightFilter"},{"location":"filters/#qcsubmit.workflow_components.filters.MolecularWeightFilter.apply","text":"Show source code in workflow_components/filters.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 def apply ( self , molecules : List [ Molecule ]) -> ComponentResult : \"\"\" The common entry point of all workflow components which applies the workflow component to the given list of molecules. Parameters: molecules: The list of molecules the component should be applied on. Returns: A [ComponentResult][qcsubmit.datasets.ComponentResult] instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result. [qcsubmit.datasets.ComponentResult] \"\"\" from simtk import unit result = self . _create_result () for molecule in molecules : total_weight = sum ( [ atom . element . mass . value_in_unit ( unit . daltons ) for atom in molecule . atoms ] ) if self . minimum_weight < total_weight < self . maximum_weight : result . add_molecule ( molecule ) else : self . fail_molecule ( molecule = molecule , component_result = result ) return result The common entry point of all workflow components which applies the workflow component to the given list of molecules. Parameters Name Type Description Default molecules List[openforcefield.topology.molecule.Molecule] The list of molecules the component should be applied on. required Returns Type Description ComponentResult A ComponentResult instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result. qcsubmit.datasets.ComponentResult","title":"apply()"},{"location":"filters/#qcsubmit.workflow_components.filters.MolecularWeightFilter.provenance","text":"Show source code in workflow_components/filters.py 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 def provenance ( self ) -> Dict : \"\"\" Generate version information for all of the software used during the running of this component. Returns: A dictionary of all of the software used in the component along wither their version numbers. Important: The simtk unit module has no version information so the version of OpenMM is given instead. \"\"\" from simtk import openmm provenance = super () . provenance () provenance [ \"openmm_units\" ] = openmm . __version__ return provenance Generate version information for all of the software used during the running of this component. Returns Type Description Dict A dictionary of all of the software used in the component along wither their version numbers. Important The simtk unit module has no version information so the version of OpenMM is given instead.","title":"provenance()"},{"location":"filters/#qcsubmit.workflow_components.filters.RotorFilter","text":"Filters molecules based on the maximum allowed number of rotatable bonds. Note Rotatable bonds are non terminal torsions found using the find_rotatable_bonds method of the openforcefield.topology.Molecule class.","title":"RotorFilter"},{"location":"filters/#qcsubmit.workflow_components.filters.RotorFilter.apply","text":"Show source code in workflow_components/filters.py 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 def apply ( self , molecules : List [ Molecule ]) -> ComponentResult : \"\"\" Apply the filter to the list of molecules to remove any molecules with more rotors then the maximum allowed number. Parameters: molecules: The list of molecules the component should be applied on. Returns: A [ComponentResult][qcsubmit.datasets.ComponentResult] instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result. \"\"\" # create the return result = self . _create_result () # run the the molecules and calculate the number of rotatable bonds for molecule in molecules : if len ( molecule . find_rotatable_bonds ()) > self . maximum_rotors : self . fail_molecule ( molecule = molecule , component_result = result ) else : result . add_molecule ( molecule ) return result Apply the filter to the list of molecules to remove any molecules with more rotors then the maximum allowed number. Parameters Name Type Description Default molecules List[openforcefield.topology.molecule.Molecule] The list of molecules the component should be applied on. required Returns Type Description ComponentResult A ComponentResult instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result.","title":"apply()"},{"location":"procedures/","text":"The procedure settings controllers GeometricProcedure \u00b6 This is a settings class controlling the various runtime options that can be used when running geometric. Attributes: program: The name of the procedure. coordsys: The name of the coordinate system which should be used during the optimisation. enforce: The threshold (in a.u /rad) to activate precise constraint satisfaction. epsilon: Small eigenvalue threshold. reset: Reset the Hessian when the eigenvalues are under epsilon. qccnv: Q-Chem style convergence criteria (i.e. gradient and either energy or displacement). molcnv: Molpro style convergence criteria (i.e. gradient and either energy or displacement, with different defaults). check: The interval for checking the coordinate system for changes. trust: Starting value of the trust radius. tmax: Maximum value of trust radius. maxiter: Maximum number of optimization cycles. convergence_set: The set of convergence criteria to be used for the optimisation. check_convergence_set ( convergence ) (classmethod) \u00b6 Show source code in qcsubmit/procedures.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 @validator ( \"convergence_set\" ) def check_convergence_set ( cls , convergence : str ): \"\"\" Ensure a valid convergence set of criteria has been passed. Parameters: convergence: The convergence criteria set, see below for allowed values. Raises: ValueError: If the convergence set is not supported. Important: Geometric currently accepts the following convergence criteria sets: | Set | Set Name | Energy | GRMS | GMAX | DRMS | DMAX | |---|---|---|---|---|---|---| | `GAU` | Gaussian default | 1e-6 | 3e-4 | 4.5e-4 | 1.2e-3 | 1.8e-3 | | `NWCHEM_LOOSE` | NW-Chem loose | 1e-6 | 3e-3 | 4.5e-3 | 3.6e-3 | 5.4e-3 | | `GAU_LOOSE` | Gaussian loose | 1e-6 | 1.7e-3 | 2.5e-3 | 6.7e-3 | 1e-2 | | `TURBOMOLE` | Turbomole default | 1e-6 | 5e-4 | 1e-3 | 5.0e-4 | 1e-3 | | `INTERFRAG_TIGHT` | Interfrag tight | 1e-6 | 1e-5 | 1.5e-5 | 4.0e-4 | 6.0e-4 | | `GAU_TIGHT` | Gaussian tight | 1e-6 | 1e-5 | 1.5e-5 | 4e-5 | 6e-5 | | `GAU_VERYTIGHT` | Gaussian very tight | 1e-6 | 1e-6 | 2e-6 | 4e-6 | 6e-6 | \"\"\" allowed_convergence = [ \"GAU\" , \"NWCHEM_LOOSE\" , \"GAU_LOOSE\" , \"TURBOMOLE\" , \"INTERFRAG_TIGHT\" , \"GAU_TIGHT\" , \"GAU_VERYTIGHT\" , ] if convergence . upper () in allowed_convergence : return convergence . upper () else : raise ValueError ( f \"The requested convergence set { convergence } is not supported.\" ) Ensure a valid convergence set of criteria has been passed. Parameters Name Type Description Default convergence str The convergence criteria set, see below for allowed values. required Exceptions Type Description ValueError If the convergence set is not supported. Important Geometric currently accepts the following convergence criteria sets: Set Set Name Energy GRMS GMAX DRMS DMAX GAU Gaussian default 1e-6 3e-4 4.5e-4 1.2e-3 1.8e-3 NWCHEM_LOOSE NW-Chem loose 1e-6 3e-3 4.5e-3 3.6e-3 5.4e-3 GAU_LOOSE Gaussian loose 1e-6 1.7e-3 2.5e-3 6.7e-3 1e-2 TURBOMOLE Turbomole default 1e-6 5e-4 1e-3 5.0e-4 1e-3 INTERFRAG_TIGHT Interfrag tight 1e-6 1e-5 1.5e-5 4.0e-4 6.0e-4 GAU_TIGHT Gaussian tight 1e-6 1e-5 1.5e-5 4e-5 6e-5 GAU_VERYTIGHT Gaussian very tight 1e-6 1e-6 2e-6 4e-6 6e-6 check_coordsys ( coordsys ) (classmethod) \u00b6 Show source code in qcsubmit/procedures.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 @validator ( \"coordsys\" ) def check_coordsys ( cls , coordsys : str ): \"\"\" Make sure the user is assigning a valid geometric coordinate system. Parameters: coordsys: The coordinate system to be used during optimisation. Raises: ValueError: If the coordinate system is not supported by geometric. Important: The coordinate systems supported by geometric are: - `cart` Cartesian - `prim` Primitive a.k.a redundant - `dlc` Delocalised Internal Coordinates - `hdlc` Hybrid Delocalised Internal Coordinates - `tric` Translation-Rotation-Internal Coordinates, this is the default default \"\"\" allowed_coordsys = [ \"cart\" , \"prim\" , \"dlc\" , \"hdlc\" , \"tric\" ] if coordsys . lower () in allowed_coordsys : return coordsys . lower () else : raise ValueError ( f \" { coordsys } is not supported by geometric please pass a valid coordinate system.\" ) Make sure the user is assigning a valid geometric coordinate system. Parameters Name Type Description Default coordsys str The coordinate system to be used during optimisation. required Exceptions Type Description ValueError If the coordinate system is not supported by geometric. Important The coordinate systems supported by geometric are: cart Cartesian prim Primitive a.k.a redundant dlc Delocalised Internal Coordinates hdlc Hybrid Delocalised Internal Coordinates tric Translation-Rotation-Internal Coordinates, this is the default default check_program ( program ) (classmethod) \u00b6 Show source code in qcsubmit/procedures.py 49 50 51 52 53 54 55 56 57 @validator ( \"program\" ) def check_program ( cls , program : str ): \"\"\" The program should not be changed from geometric. \"\"\" if program . lower () != \"geometric\" : return \"geometric\" else : return program . lower () The program should not be changed from geometric. from_opt_spec ( optimization_specification ) (classmethod) \u00b6 Show source code in qcsubmit/procedures.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 @classmethod def from_opt_spec ( cls , optimization_specification : OptimizationSpecification ) -> \"GeometricProcedure\" : \"\"\" Create a geometric procedure from an Optimization spec. \"\"\" if optimization_specification . keywords is None : return GeometricProcedure () else : data = optimization_specification . dict ( exclude = { \"program\" }) return GeometricProcedure ( ** data [ \"keywords\" ]) Create a geometric procedure from an Optimization spec. get_optimzation_spec ( self ) \u00b6 Show source code in qcsubmit/procedures.py 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 def get_optimzation_spec ( self ) -> OptimizationSpecification : \"\"\" Create the optimization specification to be used in qcarchive. Returns: A dictionary representation of the optimization specification. \"\"\" exclude = { \"program\" } if self . constraints is not None : exclude . add ( \"constraints\" ) opt_spec = OptimizationSpecification ( program = self . program , keywords = self . dict ( exclude = exclude ) ) return opt_spec Create the optimization specification to be used in qcarchive. Returns Type Description OptimizationSpecification A dictionary representation of the optimization specification.","title":"Procedures"},{"location":"procedures/#qcsubmit.procedures.GeometricProcedure","text":"This is a settings class controlling the various runtime options that can be used when running geometric. Attributes: program: The name of the procedure. coordsys: The name of the coordinate system which should be used during the optimisation. enforce: The threshold (in a.u /rad) to activate precise constraint satisfaction. epsilon: Small eigenvalue threshold. reset: Reset the Hessian when the eigenvalues are under epsilon. qccnv: Q-Chem style convergence criteria (i.e. gradient and either energy or displacement). molcnv: Molpro style convergence criteria (i.e. gradient and either energy or displacement, with different defaults). check: The interval for checking the coordinate system for changes. trust: Starting value of the trust radius. tmax: Maximum value of trust radius. maxiter: Maximum number of optimization cycles. convergence_set: The set of convergence criteria to be used for the optimisation.","title":"GeometricProcedure"},{"location":"procedures/#qcsubmit.procedures.GeometricProcedure.check_convergence_set","text":"Show source code in qcsubmit/procedures.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 @validator ( \"convergence_set\" ) def check_convergence_set ( cls , convergence : str ): \"\"\" Ensure a valid convergence set of criteria has been passed. Parameters: convergence: The convergence criteria set, see below for allowed values. Raises: ValueError: If the convergence set is not supported. Important: Geometric currently accepts the following convergence criteria sets: | Set | Set Name | Energy | GRMS | GMAX | DRMS | DMAX | |---|---|---|---|---|---|---| | `GAU` | Gaussian default | 1e-6 | 3e-4 | 4.5e-4 | 1.2e-3 | 1.8e-3 | | `NWCHEM_LOOSE` | NW-Chem loose | 1e-6 | 3e-3 | 4.5e-3 | 3.6e-3 | 5.4e-3 | | `GAU_LOOSE` | Gaussian loose | 1e-6 | 1.7e-3 | 2.5e-3 | 6.7e-3 | 1e-2 | | `TURBOMOLE` | Turbomole default | 1e-6 | 5e-4 | 1e-3 | 5.0e-4 | 1e-3 | | `INTERFRAG_TIGHT` | Interfrag tight | 1e-6 | 1e-5 | 1.5e-5 | 4.0e-4 | 6.0e-4 | | `GAU_TIGHT` | Gaussian tight | 1e-6 | 1e-5 | 1.5e-5 | 4e-5 | 6e-5 | | `GAU_VERYTIGHT` | Gaussian very tight | 1e-6 | 1e-6 | 2e-6 | 4e-6 | 6e-6 | \"\"\" allowed_convergence = [ \"GAU\" , \"NWCHEM_LOOSE\" , \"GAU_LOOSE\" , \"TURBOMOLE\" , \"INTERFRAG_TIGHT\" , \"GAU_TIGHT\" , \"GAU_VERYTIGHT\" , ] if convergence . upper () in allowed_convergence : return convergence . upper () else : raise ValueError ( f \"The requested convergence set { convergence } is not supported.\" ) Ensure a valid convergence set of criteria has been passed. Parameters Name Type Description Default convergence str The convergence criteria set, see below for allowed values. required Exceptions Type Description ValueError If the convergence set is not supported. Important Geometric currently accepts the following convergence criteria sets: Set Set Name Energy GRMS GMAX DRMS DMAX GAU Gaussian default 1e-6 3e-4 4.5e-4 1.2e-3 1.8e-3 NWCHEM_LOOSE NW-Chem loose 1e-6 3e-3 4.5e-3 3.6e-3 5.4e-3 GAU_LOOSE Gaussian loose 1e-6 1.7e-3 2.5e-3 6.7e-3 1e-2 TURBOMOLE Turbomole default 1e-6 5e-4 1e-3 5.0e-4 1e-3 INTERFRAG_TIGHT Interfrag tight 1e-6 1e-5 1.5e-5 4.0e-4 6.0e-4 GAU_TIGHT Gaussian tight 1e-6 1e-5 1.5e-5 4e-5 6e-5 GAU_VERYTIGHT Gaussian very tight 1e-6 1e-6 2e-6 4e-6 6e-6","title":"check_convergence_set()"},{"location":"procedures/#qcsubmit.procedures.GeometricProcedure.check_coordsys","text":"Show source code in qcsubmit/procedures.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 @validator ( \"coordsys\" ) def check_coordsys ( cls , coordsys : str ): \"\"\" Make sure the user is assigning a valid geometric coordinate system. Parameters: coordsys: The coordinate system to be used during optimisation. Raises: ValueError: If the coordinate system is not supported by geometric. Important: The coordinate systems supported by geometric are: - `cart` Cartesian - `prim` Primitive a.k.a redundant - `dlc` Delocalised Internal Coordinates - `hdlc` Hybrid Delocalised Internal Coordinates - `tric` Translation-Rotation-Internal Coordinates, this is the default default \"\"\" allowed_coordsys = [ \"cart\" , \"prim\" , \"dlc\" , \"hdlc\" , \"tric\" ] if coordsys . lower () in allowed_coordsys : return coordsys . lower () else : raise ValueError ( f \" { coordsys } is not supported by geometric please pass a valid coordinate system.\" ) Make sure the user is assigning a valid geometric coordinate system. Parameters Name Type Description Default coordsys str The coordinate system to be used during optimisation. required Exceptions Type Description ValueError If the coordinate system is not supported by geometric. Important The coordinate systems supported by geometric are: cart Cartesian prim Primitive a.k.a redundant dlc Delocalised Internal Coordinates hdlc Hybrid Delocalised Internal Coordinates tric Translation-Rotation-Internal Coordinates, this is the default default","title":"check_coordsys()"},{"location":"procedures/#qcsubmit.procedures.GeometricProcedure.check_program","text":"Show source code in qcsubmit/procedures.py 49 50 51 52 53 54 55 56 57 @validator ( \"program\" ) def check_program ( cls , program : str ): \"\"\" The program should not be changed from geometric. \"\"\" if program . lower () != \"geometric\" : return \"geometric\" else : return program . lower () The program should not be changed from geometric.","title":"check_program()"},{"location":"procedures/#qcsubmit.procedures.GeometricProcedure.from_opt_spec","text":"Show source code in qcsubmit/procedures.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 @classmethod def from_opt_spec ( cls , optimization_specification : OptimizationSpecification ) -> \"GeometricProcedure\" : \"\"\" Create a geometric procedure from an Optimization spec. \"\"\" if optimization_specification . keywords is None : return GeometricProcedure () else : data = optimization_specification . dict ( exclude = { \"program\" }) return GeometricProcedure ( ** data [ \"keywords\" ]) Create a geometric procedure from an Optimization spec.","title":"from_opt_spec()"},{"location":"procedures/#qcsubmit.procedures.GeometricProcedure.get_optimzation_spec","text":"Show source code in qcsubmit/procedures.py 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 def get_optimzation_spec ( self ) -> OptimizationSpecification : \"\"\" Create the optimization specification to be used in qcarchive. Returns: A dictionary representation of the optimization specification. \"\"\" exclude = { \"program\" } if self . constraints is not None : exclude . add ( \"constraints\" ) opt_spec = OptimizationSpecification ( program = self . program , keywords = self . dict ( exclude = exclude ) ) return opt_spec Create the optimization specification to be used in qcarchive. Returns Type Description OptimizationSpecification A dictionary representation of the optimization specification.","title":"get_optimzation_spec()"},{"location":"state_enumeration/","text":"Components to expand stereochemistry and tautomeric states of molecules. EnumerateProtomers \u00b6 Enumerate the formal charges of the input molecule using the backend toolkits through the OFFTK. Note Only Openeye is supported so far. apply ( self , molecules ) \u00b6 Show source code in workflow_components/state_enumeration.py 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 def apply ( self , molecules : List [ Molecule ]) -> ComponentResult : \"\"\" Enumerate the formal charges of the molecule if possible if not only the input molecule is returned. Parameters: molecules: The list of molecules the component should be applied on. Returns: A [ComponentResult][qcsubmit.datasets.ComponentResult] instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result. Important: This is only possible using Openeye so far, if openeye is not available this step will fail. \"\"\" from openforcefield.utils.toolkits import OpenEyeToolkitWrapper result = self . _create_result () # must have openeye to use this feature if OpenEyeToolkitWrapper . is_available (): for molecule in molecules : try : protomers = molecule . enumerate_protomers ( max_states = self . max_states ) for protomer in protomers : result . add_molecule ( protomer ) result . add_molecule ( molecule ) except Exception : self . fail_molecule ( molecule = molecule , component_result = result ) return result else : for molecule in molecules : self . fail_molecule ( molecule = molecule , component_result = result ) return result Enumerate the formal charges of the molecule if possible if not only the input molecule is returned. Parameters Name Type Description Default molecules List[openforcefield.topology.molecule.Molecule] The list of molecules the component should be applied on. required Returns Type Description ComponentResult A ComponentResult instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result. Important This is only possible using Openeye so far, if openeye is not available this step will fail. EnumerateStereoisomers \u00b6 Enumerate the stereo centers and bonds of a molecule using the backend toolkits through the OFFTK. Attributes: undefined_only: bool, default=False If we should only enumerate undefined stereo centers and bonds or not. max_isomers: int, default=20 The maximum amount of isomers to be generated by the component. rationalise: bool, default=True Try and generate a conformer for the molecule to rationalise it. include_input: bool, default=True If the input molecule should be included in the result or not. toolkit: str, default='openeye' The backend toolkit to be used by the OFFTK. Note The provenance information and toolkit settings are handled by the ToolkitValidator mixin. apply ( self , molecules ) \u00b6 Show source code in workflow_components/state_enumeration.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 def apply ( self , molecules : List [ Molecule ]) -> ComponentResult : \"\"\" Enumerate stereo centers and bonds of the input molecule if no isomers are found only the input molecule is returned. Parameters: molecules: The list of molecules the component should be applied on. Returns: A [ComponentResult][qcsubmit.datasets.ComponentResult] instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result. \"\"\" result = self . _create_result () toolkit = self . _toolkits [ self . toolkit ]() for molecule in molecules : try : isomers = molecule . enumerate_stereoisomers ( undefined_only = self . undefined_only , max_isomers = self . max_isomers , rationalise = self . rationalise , toolkit_registry = toolkit , ) if self . include_input : result . add_molecule ( molecule ) for isomer in isomers : result . add_molecule ( isomer ) except Exception : self . fail_molecule ( molecule = molecule , component_result = result ) return result Enumerate stereo centers and bonds of the input molecule if no isomers are found only the input molecule is returned. Parameters Name Type Description Default molecules List[openforcefield.topology.molecule.Molecule] The list of molecules the component should be applied on. required Returns Type Description ComponentResult A ComponentResult instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result. EnumerateTautomers \u00b6 Enumerate the tautomers of a molecule using the backend toolkits through the OFFTK. Attributes: max_tautomers: int, default=20 The maximum amount of tautomers to be made by the component per molecule. toolkit: str, default='openeye' The backend toolkit to be used by the OFFTK. Note The provenance information and toolkit settings are handled by the ToolkitValidator mixin. apply ( self , molecules ) \u00b6 Show source code in workflow_components/state_enumeration.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 def apply ( self , molecules : List [ Molecule ]) -> ComponentResult : \"\"\" Enumerate tautomers of the input molecule if no tautomers are found only the input molecule is returned. Parameters: molecules: The list of molecules the component should be applied on. Returns: A [ComponentResult][qcsubmit.datasets.ComponentResult] instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result. \"\"\" result = self . _create_result () toolkit = self . _toolkits [ self . toolkit ]() for molecule in molecules : try : tautomers = molecule . enumerate_tautomers ( max_states = self . max_tautomers , toolkit_registry = toolkit ) result . add_molecule ( molecule ) for taut in tautomers : result . add_molecule ( taut ) except Exception : self . fail_molecule ( molecule , component_result = result ) return result Enumerate tautomers of the input molecule if no tautomers are found only the input molecule is returned. Parameters: molecules: The list of molecules the component should be applied on. Returns Type Description ComponentResult A ComponentResult instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result.","title":"State Enumeration"},{"location":"state_enumeration/#qcsubmit.workflow_components.state_enumeration.EnumerateProtomers","text":"Enumerate the formal charges of the input molecule using the backend toolkits through the OFFTK. Note Only Openeye is supported so far.","title":"EnumerateProtomers"},{"location":"state_enumeration/#qcsubmit.workflow_components.state_enumeration.EnumerateProtomers.apply","text":"Show source code in workflow_components/state_enumeration.py 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 def apply ( self , molecules : List [ Molecule ]) -> ComponentResult : \"\"\" Enumerate the formal charges of the molecule if possible if not only the input molecule is returned. Parameters: molecules: The list of molecules the component should be applied on. Returns: A [ComponentResult][qcsubmit.datasets.ComponentResult] instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result. Important: This is only possible using Openeye so far, if openeye is not available this step will fail. \"\"\" from openforcefield.utils.toolkits import OpenEyeToolkitWrapper result = self . _create_result () # must have openeye to use this feature if OpenEyeToolkitWrapper . is_available (): for molecule in molecules : try : protomers = molecule . enumerate_protomers ( max_states = self . max_states ) for protomer in protomers : result . add_molecule ( protomer ) result . add_molecule ( molecule ) except Exception : self . fail_molecule ( molecule = molecule , component_result = result ) return result else : for molecule in molecules : self . fail_molecule ( molecule = molecule , component_result = result ) return result Enumerate the formal charges of the molecule if possible if not only the input molecule is returned. Parameters Name Type Description Default molecules List[openforcefield.topology.molecule.Molecule] The list of molecules the component should be applied on. required Returns Type Description ComponentResult A ComponentResult instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result. Important This is only possible using Openeye so far, if openeye is not available this step will fail.","title":"apply()"},{"location":"state_enumeration/#qcsubmit.workflow_components.state_enumeration.EnumerateStereoisomers","text":"Enumerate the stereo centers and bonds of a molecule using the backend toolkits through the OFFTK. Attributes: undefined_only: bool, default=False If we should only enumerate undefined stereo centers and bonds or not. max_isomers: int, default=20 The maximum amount of isomers to be generated by the component. rationalise: bool, default=True Try and generate a conformer for the molecule to rationalise it. include_input: bool, default=True If the input molecule should be included in the result or not. toolkit: str, default='openeye' The backend toolkit to be used by the OFFTK. Note The provenance information and toolkit settings are handled by the ToolkitValidator mixin.","title":"EnumerateStereoisomers"},{"location":"state_enumeration/#qcsubmit.workflow_components.state_enumeration.EnumerateStereoisomers.apply","text":"Show source code in workflow_components/state_enumeration.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 def apply ( self , molecules : List [ Molecule ]) -> ComponentResult : \"\"\" Enumerate stereo centers and bonds of the input molecule if no isomers are found only the input molecule is returned. Parameters: molecules: The list of molecules the component should be applied on. Returns: A [ComponentResult][qcsubmit.datasets.ComponentResult] instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result. \"\"\" result = self . _create_result () toolkit = self . _toolkits [ self . toolkit ]() for molecule in molecules : try : isomers = molecule . enumerate_stereoisomers ( undefined_only = self . undefined_only , max_isomers = self . max_isomers , rationalise = self . rationalise , toolkit_registry = toolkit , ) if self . include_input : result . add_molecule ( molecule ) for isomer in isomers : result . add_molecule ( isomer ) except Exception : self . fail_molecule ( molecule = molecule , component_result = result ) return result Enumerate stereo centers and bonds of the input molecule if no isomers are found only the input molecule is returned. Parameters Name Type Description Default molecules List[openforcefield.topology.molecule.Molecule] The list of molecules the component should be applied on. required Returns Type Description ComponentResult A ComponentResult instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result.","title":"apply()"},{"location":"state_enumeration/#qcsubmit.workflow_components.state_enumeration.EnumerateTautomers","text":"Enumerate the tautomers of a molecule using the backend toolkits through the OFFTK. Attributes: max_tautomers: int, default=20 The maximum amount of tautomers to be made by the component per molecule. toolkit: str, default='openeye' The backend toolkit to be used by the OFFTK. Note The provenance information and toolkit settings are handled by the ToolkitValidator mixin.","title":"EnumerateTautomers"},{"location":"state_enumeration/#qcsubmit.workflow_components.state_enumeration.EnumerateTautomers.apply","text":"Show source code in workflow_components/state_enumeration.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 def apply ( self , molecules : List [ Molecule ]) -> ComponentResult : \"\"\" Enumerate tautomers of the input molecule if no tautomers are found only the input molecule is returned. Parameters: molecules: The list of molecules the component should be applied on. Returns: A [ComponentResult][qcsubmit.datasets.ComponentResult] instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result. \"\"\" result = self . _create_result () toolkit = self . _toolkits [ self . toolkit ]() for molecule in molecules : try : tautomers = molecule . enumerate_tautomers ( max_states = self . max_tautomers , toolkit_registry = toolkit ) result . add_molecule ( molecule ) for taut in tautomers : result . add_molecule ( taut ) except Exception : self . fail_molecule ( molecule , component_result = result ) return result Enumerate tautomers of the input molecule if no tautomers are found only the input molecule is returned. Parameters: molecules: The list of molecules the component should be applied on. Returns Type Description ComponentResult A ComponentResult instance containing information about the molecules that passed and were filtered by the component and details about the component which generated the result.","title":"apply()"}]}